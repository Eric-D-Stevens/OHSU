{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch - A Quick Walkthrough\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is a Python library for numerical computing and neural networks. Notably, it supports the automatic differentiation behavior that we discussed in class. What does this mean? It means that you can set up arbitrarily complex computational graphs, and PyTorch will take care of differentiating their contents.\n",
    "\n",
    "## 1. Installation!\n",
    "\n",
    "Installation is simple, and can be done using either Pip or Anaconda. The PyTorch homepage has a [helpful installation](https://pytorch.org/#pip-install-pytorch) tool that will help you figure out what the right way will be to install it on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/47/068dc7020fd8cf89cca74a16690e274fb55c08684bcaece11348d98264f0/torch-1.0.0-cp36-none-macosx_10_7_x86_64.whl (61.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 61.4MB 500kB/s ta 0:00:011   11% |███▋                            | 6.9MB 8.8MB/s eta 0:00:07    82% |██████████████████████████▌     | 50.9MB 8.9MB/s eta 0:00:02\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "Successfully installed torch-1.0.0\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've got PyTorch installed, import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. First steps\n",
    "\n",
    "They key data structure in PyTorch is the [`Tensor`](https://pytorch.org/docs/stable/tensors.html), which represents a tensor (loosely, a matrix of arbitrary dimension) that keeps track of its own gradient and can be part of a computational graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9793, 0.8003, 0.4017, 0.3917])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.rand(4)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that we have created a tensor, populated with 4 random numbers. Each tensor has a `size` attribute, indicating its dimensionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tensor has one dimension, and has 4 elements in that single dimension. We can create a multidimensional random tensor like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9678, 0.0727, 0.8545, 0.2159],\n",
       "        [0.9644, 0.3299, 0.8747, 0.6461]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = torch.rand(2, 4) # make a random 2x4 matrix\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tensor has _two_ dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to create a tensor directly from already-existing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_data = [1,2,3,4]\n",
    "some_tensor = torch.tensor(some_data)\n",
    "some_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3]]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works with numpy data, as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0, 2, 2, 3, 2, 2, 2, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy_random = np.random.randint(4, size=10)\n",
    "numpy_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 0, 2, 2, 3, 2, 2, 2, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(numpy_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 0, 2, 2, 3, 2, 2, 2, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(numpy_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can go _back_ into numpy, if for some reason you need that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly, this is un-necessary, as PyTorch tensors support much of the same functionality as Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.sum().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.sum().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[[[3]]]]).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can have data types, specified very similarly to how it is done in Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_tensor = torch.tensor([1,2,3], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functionality is only implemented on certain types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.6931, 1.0986])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"log\" not implemented for 'torch.LongTensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1db4d96ac980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msome_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this won't work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: \"log\" not implemented for 'torch.LongTensor'"
     ]
    }
   ],
   "source": [
    "some_tensor.log() # this won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.6931, 1.0986, 1.3863])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.float().log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, of course, do arithemtic with tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 2.0500, 3.6000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 2.3, 4.6])\n",
    "b = torch.tensor([0.5, 0.25, 1.0])\n",
    "a-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, if you are using a GPU, tensors can be transparently used on either the CPU or the GPU; memory allocation, etc. will all be done automatically, and if the arithmetic operations you are requesting are available in CUDA, the appropriate kernel will be run for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy-style array sicing works, and in multiple dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2058, 0.2561, 0.2890, 0.5718, 0.0019, 0.2015],\n",
       "        [0.4666, 0.6876, 0.1284, 0.7160, 0.6759, 0.1741],\n",
       "        [0.3859, 0.2905, 0.3306, 0.3916, 0.2289, 0.9220],\n",
       "        [0.3225, 0.4572, 0.1637, 0.3651, 0.7408, 0.6764]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3 = torch.rand(4,6)\n",
    "r3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4666, 0.6876, 0.1284, 0.7160, 0.6759, 0.1741])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2890, 0.1284, 0.3306, 0.1637])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3225, 0.4572, 0.1637, 0.3651, 0.7408, 0.6764])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix and vector operations are, of course supported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  4,  9, 16])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.tensor([1,2,3,4])\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 12, 21, 32]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.tensor([[5,6,7,8]]) # a 1x4 matrix\n",
    "c * a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `unsqueeze()` function to turn vectors into matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_mat = a.unsqueeze(0)\n",
    "a_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_mat.shape: torch.Size([1, 4])\n",
      "c.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"a_mat.shape: {a_mat.shape}\")\n",
    "print(f\"c.shape: {c.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6,  7,  8],\n",
       "        [10, 12, 14, 16],\n",
       "        [15, 18, 21, 24],\n",
       "        [20, 24, 28, 32]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_mat.t() @ c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want to or can't use Python 3's matrix multiplication operator, there is a `matmul` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6,  7,  8],\n",
       "        [10, 12, 14, 16],\n",
       "        [15, 18, 21, 24],\n",
       "        [20, 24, 28, 32]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_mat.t().matmul(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variety of \"reduction\" operators are included, as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting things together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_dot_b = (a * b).sum()\n",
    "a_dot_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, dot (inner) product is also included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dot(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradients\n",
    "\n",
    "One notable thing about PyTorch tensors (and PyTorch's various arithmetic operators!) is that they keep track of their gradients. This is, of course, important for neural network training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "y = torch.tensor(2.0, requires_grad=True)\n",
    "z = torch.tensor(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x + y\n",
    "b = torch.max(y, z)\n",
    "f = a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.retain_grad() # tell PyTorch to retain gradients from f's computational history\n",
    "f.backward() # calculate gradients relative to f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(f.grad) # df/df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad # df/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad # df/dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad # df/dz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing you'll note is that PyTorch goes out of its way to be efficient- for a large network, keeping around all gradients would quickly become prohibitive in terms of memory usage, so by default it only keeps around the bare minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimization\n",
    "\n",
    "Let's try implementing a multinomial logistic regression classifier. Recall that logistic regression looks like so:\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{x*w_c^T+b}}{\\sum^{C}_{j=1}e^{x*w_j^T+b}}$$\n",
    "\n",
    "This is equivalent to:\n",
    "\n",
    "$$\\hat{y}=\\log \\text{softmax}(w^T*x+b)$$\n",
    "\n",
    "We need to learn the parameters of the matrix $w$ and bias term $b$, and do so by minimizing the negativel log-likelihood of $\\hat{y}$.\n",
    "\n",
    "PyTorch comes with implementations of several optimization algorithms that we can use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_x = iris['data']\n",
    "iris_y = iris['target']\n",
    "iris_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([50, 50, 50]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(iris_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a 75/25 train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.arange(iris_x.shape[0]) % 4 != 0 # get an array where every fourth item is marked for inclusion in test\n",
    "iris_x_train_np, iris_y_train_np = iris_x[train_idx, :], iris_y[train_idx]\n",
    "iris_x_test_np, iris_y_test_np = iris_x[~train_idx, :], iris_y[~train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn these straight into PyTorch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_x_train, iris_y_train = torch.from_numpy(iris_x_train_np), torch.from_numpy(iris_y_train_np)\n",
    "iris_x_test, iris_y_test = torch.from_numpy(iris_x_test_np), torch.from_numpy(iris_y_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `from_numpy()` by default matches `dtype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_x_test_np.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_x_test.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can set up our parameters, starting with a random initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand(3,4, dtype=torch.float64)\n",
    "b = torch.rand(3, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's set up a loss function, as well as import a utility function package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.NLLLoss() # negative log likelihood loss- PyTorch comes with many others out of the box\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall procedure will be:\n",
    "\n",
    "1. Make a prediction\n",
    "2. Compute loss\n",
    "3. Update\n",
    "4. Repeat\n",
    "\n",
    "Let's see what that looks like for one run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = iris_x_train @ w.t() + b\n",
    "y_hat = F.log_softmax(z, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that this worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, dtype=torch.float64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0].exp().sum() # should be 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute loss.  The loss functions in PyTorch are a bit finicky about their dimensions- the key is that the prediction must be $N \\times C$, and the target must be $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1504, dtype=torch.float64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(y_hat[0].unsqueeze(0), iris_y_train[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're not pulling out individual items, it's all a lot easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2937, dtype=torch.float64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(y_hat[:4], iris_y_train[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can compute it on an entire training set at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0352, dtype=torch.float64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(y_hat, iris_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at that loss function for the subset of the data that was correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3610, dtype=torch.float64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func( y_hat[:37], iris_y_train[:37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([112, 3])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_hat.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got our loss calculation, but it would be helpful to have a way to evaluate our parameter's accuracy as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_acc(y_hat_, y_):\n",
    "    n_correct = (y_hat_.argmax(dim=1) == y_).sum().float()\n",
    "    n_total = float(len(y_))\n",
    "    return (n_correct / n_total).item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_acc(y_hat, iris_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense, since we are working with random weights- we'd expect to get chance accuracy. Let's try optimizing our parameters!\n",
    "\n",
    "Now, we set up an optimizer and training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-initialize our parameters, this time making sure that they keep track of their gradients:\n",
    "\n",
    "w = torch.rand(3,4, dtype=torch.float64, requires_grad=True)\n",
    "b = torch.rand(3, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "sgd_opt = torch.optim.SGD([w, b], lr=0.01) # can experiment with different learning rates\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "stored_perf = [] # for graphing our progress\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    sgd_opt.zero_grad() # erase any gradients our optimizer might remember\n",
    "    \n",
    "    # do a forward pass through our data:\n",
    "    z = iris_x_train @ w.t() + b\n",
    "    y_hat = F.log_softmax(z, dim=1)\n",
    "    \n",
    "    loss = loss_func(y_hat, iris_y_train)\n",
    "    \n",
    "    # send back gradients:\n",
    "    loss.backward()\n",
    "    \n",
    "    # now, tell the optimizer to update our weights:\n",
    "    sgd_opt.step()\n",
    "\n",
    "    epoch_acc = eval_acc(y_hat, iris_y_train)\n",
    "    \n",
    "    # also compute loss on our test data\n",
    "    y_hat_test = F.log_softmax(iris_x_test @ w.t() + b, dim=1)\n",
    "    loss_test = loss_func(y_hat_test, iris_y_test)\n",
    "    acc_test = eval_acc(y_hat_test, iris_y_test)\n",
    "    \n",
    "    stored_perf.append([i, loss.item(), epoch_acc, loss_test.item(), acc_test])\n",
    "    \n",
    "    # print out how we're doing:\n",
    "    if i % 100 == 0:\n",
    "        print(f\"epoch {i}, training loss: {loss}, train acc: {eval_acc(y_hat, iris_y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a few plots, just for fun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pylab import plt\n",
    "\n",
    "perf_df = pd.DataFrame(stored_perf, columns=[\"epoch\",\"train loss\",\"train acc\", \"test loss\", \"test acc\"])\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "perf_df[[\"train loss\", \"test loss\"]].plot(ax=ax1);\n",
    "perf_df[[\"train acc\", \"test acc\"]].plot(ax=ax2);\n",
    "ax1.set_ylim([0,6]);\n",
    "ax2.set_ylim([0,1]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has built-in classes to do a lot of this work for us. For very simple models like the one above, it doesn't make a huge difference, but as models grow in complexity, it can be extremely helpful!\n",
    "\n",
    "For example, instead of manually performing the matrix multiplication and bias addition, we can use the `linear()` function from `torch.nn.functional`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = F.linear(iris_x_train, w, bias=b)\n",
    "y_hat = F.log_softmax(z, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to use the `nn` package's classes to wrap our model functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since our data is coming from Numpy, and it defaults to doubles, we need to tell our model to match:\n",
    "linear_layer = nn.Linear(4,3).double() # input features, output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_opt = torch.optim.SGD(linear_layer.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    sgd_opt.zero_grad() # erase any gradients our optimizer might remember\n",
    "    \n",
    "    # do a forward pass through our data:\n",
    "    z = linear_layer(iris_x_train)\n",
    "    y_hat = F.log_softmax(z, dim=1)\n",
    "    \n",
    "    loss = loss_func(y_hat, iris_y_train)\n",
    "    \n",
    "    # send back gradients:\n",
    "    loss.backward()\n",
    "    \n",
    "    # now, tell the optimizer to update our weights:\n",
    "    sgd_opt.step()\n",
    "\n",
    "    epoch_acc = eval_acc(y_hat, iris_y_train)\n",
    "    \n",
    "    # print out how we're doing:\n",
    "    if i % 100 == 0:\n",
    "        print(f\"epoch {i}, training loss: {loss}, train acc: {eval_acc(y_hat, iris_y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had more going on our model, this would ake for cleaner code. We can get even more modular, but using the `nn.Module` class to group layers and functions. Note that our `Module` is just a Python class, so we can e.g. specify parameters for network dimensionality, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self, input_dims, output_classes):\n",
    "        super(LogReg, self).__init__()\n",
    "        self.linear = nn.Linear(input_dims, output_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.linear(x)\n",
    "        return F.log_softmax(z, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use our `LogReg` class just like we did when we were just using `Linear` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogReg(4,3).double()\n",
    "\n",
    "list(log_reg.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogReg(4,3).double()\n",
    "\n",
    "sgd_opt = torch.optim.SGD(log_reg.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    sgd_opt.zero_grad() # erase any gradients our optimizer might remember\n",
    "    \n",
    "    # do a forward pass through our data:\n",
    "    y_hat = log_reg(iris_x_train) # note that we don't need to call softmax here anymore!\n",
    "    \n",
    "    loss = loss_func(y_hat, iris_y_train)\n",
    "    \n",
    "    # send back gradients:\n",
    "    loss.backward()\n",
    "    \n",
    "    # now, tell the optimizer to update our weights:\n",
    "    sgd_opt.step()\n",
    "\n",
    "    epoch_acc = eval_acc(y_hat, iris_y_train)\n",
    "    \n",
    "    # print out how we're doing:\n",
    "    if i % 100 == 0:\n",
    "        print(f\"epoch {i}, training loss: {loss}, train acc: {eval_acc(y_hat, iris_y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had a more complex model, we could encapsulate it and protect the rest of our code from knowing about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.h1 = nn.Linear(input_dims, hidden_dims)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.h2 = nn.Linear(hidden_dims, output_classes)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.h1(x)\n",
    "        out = self.activation(out) # transform to representation space\n",
    "        out = self.h2(out) # perform classification on representation\n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Module`s can contain other `Module`s, and so on. Note that we use it _exactly_ as before. Through the magic of class inheritance, PyTorch knows how to take the gradient of all of the individual pieces in our model, and it all Just Works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(4, 6, 3).double() # six hidden dims?\n",
    "\n",
    "sgd_opt = torch.optim.SGD(mlp.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    sgd_opt.zero_grad() # erase any gradients our optimizer might remember\n",
    "    \n",
    "    # do a forward pass through our data:\n",
    "    y_hat = mlp(iris_x_train) # note that we don't need to call softmax here anymore!\n",
    "    \n",
    "    loss = loss_func(y_hat, iris_y_train)\n",
    "    \n",
    "    # send back gradients:\n",
    "    loss.backward()\n",
    "    \n",
    "    # now, tell the optimizer to update our weights:\n",
    "    sgd_opt.step()\n",
    "\n",
    "    epoch_acc = eval_acc(y_hat, iris_y_train)\n",
    "    \n",
    "    # print out how we're doing:\n",
    "    if i % 100 == 0:\n",
    "        print(f\"epoch {i}, training loss: {loss}, train acc: {eval_acc(y_hat, iris_y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try training a simple LSTM to do language identification. Since the point of this lab is about PyTorch and not data wrangling, I've encaspulated some code to download and process the data, and put it in a separate file; in the assignment, you will write your own versions of this code. Since you don't have that file, this part of the notebook cannot be run as-is, and so I have left the output in here as an illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6412825</td>\n",
       "      <td>eng</td>\n",
       "      <td>Mary needed someone to help her with her homew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011404</td>\n",
       "      <td>eng</td>\n",
       "      <td>I want my key back.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60568</td>\n",
       "      <td>eng</td>\n",
       "      <td>These plums are ripe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3133583</td>\n",
       "      <td>eng</td>\n",
       "      <td>That's what happens when you lend things to pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7388954</td>\n",
       "      <td>eng</td>\n",
       "      <td>She's going to tear her house down.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id lang                                           sentence\n",
       "0  6412825  eng  Mary needed someone to help her with her homew...\n",
       "1  2011404  eng                                I want my key back.\n",
       "2    60568  eng                              These plums are ripe.\n",
       "3  3133583  eng  That's what happens when you lend things to pe...\n",
       "4  7388954  eng                She's going to tear her house down."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"merged.csv\")\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from util import prep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2i, i2c = prep_data.build_char_vocab(df)\n",
    "l2i, i2l = prep_data.build_label_vocab(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_sentence = df.head().iloc[0].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  6,  7,  6,  7,  4,  8,  9, 10,  6,  9,  5,\n",
       "         6,  4, 11,  9,  4, 12,  6, 13, 14,  4, 12,  6,  2,  4, 15, 16, 11, 12,\n",
       "         4, 12,  6,  2,  4, 12,  9, 10,  6, 15,  9,  2, 17, 18])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_data.sentence2tensor(some_sentence, c2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0,  1,  2,  3,  4,  5,  6,  6,  7,  6,  7,  4,  8,  9, 10,  6,  9,  5,\n",
       "          6,  4, 11,  9,  4, 12,  6, 13, 14,  4, 12,  6,  2,  4, 15, 16, 11, 12,\n",
       "          4, 12,  6,  2,  4, 12,  9, 10,  6, 15,  9,  2, 17, 18])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[prep_data.sentence2tensor(s, c2i) for s in df[:1].sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set up a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(prep_data)\n",
    "li = prep_data.LangID(len(c2i), 10, 20, len(l2i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, query it on our sample sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = li(prep_data.sentence2tensor(some_sentence, c2i).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these are log-probabilities; let's exponentiate to see real-space probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5639, 0.4361], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have not trained our model, the results here should be pretty random. Let's train using the [ADAM optimizer](https://arxiv.org/abs/1412.6980) (Kingma & Ba, 2015). The process is virtually identical to what we did for our logistic regression model above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per-item loss: 0.007963231764733791, 0/20000\n",
      "per-item loss: 0.6847856640815735, 1000/20000\n",
      "per-item loss: 0.6775606274604797, 2000/20000\n",
      "per-item loss: 0.6763826012611389, 3000/20000\n",
      "per-item loss: 0.6502791047096252, 4000/20000\n",
      "per-item loss: 0.6426841616630554, 5000/20000\n",
      "per-item loss: 0.6270484924316406, 6000/20000\n",
      "per-item loss: 0.6044856905937195, 7000/20000\n",
      "per-item loss: 0.5271546840667725, 8000/20000\n",
      "per-item loss: 0.48755383491516113, 9000/20000\n",
      "per-item loss: 0.39829960465431213, 10000/20000\n",
      "per-item loss: 0.39431822299957275, 11000/20000\n",
      "per-item loss: 0.39963480830192566, 12000/20000\n",
      "per-item loss: 0.31801536679267883, 13000/20000\n",
      "per-item loss: 0.280678927898407, 14000/20000\n",
      "per-item loss: 0.240852952003479, 15000/20000\n",
      "per-item loss: 0.20132911205291748, 16000/20000\n",
      "per-item loss: 0.26558351516723633, 17000/20000\n",
      "per-item loss: 0.28937503695487976, 18000/20000\n",
      "per-item loss: 0.22459350526332855, 19000/20000\n"
     ]
    }
   ],
   "source": [
    "adam_opt = torch.optim.Adam(li.parameters())\n",
    "\n",
    "num_epochs = 1\n",
    "batch_size = 100\n",
    "\n",
    "loss_func = torch.nn.NLLLoss() # since our model gives negative log probs on the output side\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    training_data_x = df.sentence.values\n",
    "    training_data_y = df.lang.values\n",
    "    \n",
    "    pairs = list(zip(training_data_x, training_data_y))\n",
    "    random.shuffle(pairs)\n",
    "    \n",
    "\n",
    "    adam_opt.zero_grad() # erase any gradients our optimizer might remember\n",
    "    loss = 0\n",
    "    \n",
    "    for x_idx, (x, y) in enumerate(pairs):\n",
    "        \n",
    "        if x_idx % batch_size == 0 and x_idx > 0:\n",
    "            adam_opt.zero_grad()\n",
    "            \n",
    "        \n",
    "        x_tens = prep_data.sentence2tensor(x, c2i).unsqueeze(0)\n",
    "        \n",
    "        y_hat = li(x_tens)\n",
    "        \n",
    "        y_tens = torch.tensor(l2i[y])\n",
    "        \n",
    "        loss += loss_func(y_hat.unsqueeze(0), y_tens.unsqueeze(0))\n",
    "    \n",
    "        if x_idx % 1000 == 0:\n",
    "            print(f\"per-item loss: {loss.float() / batch_size}, {x_idx}/{len(pairs)}\")\n",
    "    \n",
    "        # send back gradients:\n",
    "        if x_idx % batch_size == 0 and x_idx > 0:\n",
    "            loss.backward()\n",
    "            # now, tell the optimizer to update our weights:\n",
    "            adam_opt.step()\n",
    "            loss = 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it out on an English sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0690, -2.7084])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    lang_probs = li(prep_data.sentence2tensor(\"hello this is an English sentence\", c2i).unsqueeze(0))\n",
    "    print(lang_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eng'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2l[lang_probs.argmax().item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And on a Spanish one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4572, -0.2651], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_probs = li(prep_data.sentence2tensor(\"¡Hola! Español es un idioma muy interesante\", c2i).unsqueeze(0))\n",
    "lang_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spa'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2l[lang_probs.argmax().item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the implementation I've demonstrated here, I'm initializing the RNN's hidden state with random noise. This can help speed up training and improve accuracy, but it does mean that inference is not determinstic- meaning that the same input may give slightly different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
