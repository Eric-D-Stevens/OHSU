{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 562 Homework 6: The Probabilistic CKY Parsing Algorithm\n",
    "### Eric D. Stevens\n",
    "### March 4, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree\n",
    "from importlib import reload\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PCFG Generation\n",
    "\n",
    "### 1.1 Program\n",
    "\n",
    "For this entire assignment I found it easier and more elegant to modify the `Tree` class rather than making indeppendent code. Since it is sesired to check the logic of the PCFG generation against the provided example before moving on to creating a larger PCFG from an eitire corpus, two methods are implemnted in this section. The first is an implementation of the PCFG builder as a member function '`Tree`. This can be called on any `Tree` object with now arguments. The second version is class method that will create the PCFG from a file stream using the `from_stream` functions implemented in HW5. Both of these methods will return an object of type `defalutdict{defaultdict{non-terminal: daughters}}`.\n",
    "\n",
    "#### 1.1.1 Member function for single tree to PCFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This code should not be run in the notebook. The code\n",
    "here is just a compiled version of my work, seperated form \n",
    "the rest of the code for easy viewing. See how the code is\n",
    "utilized in the following section.'''\n",
    "\n",
    "\n",
    "    def MLE_PCFG(self):\n",
    "        '''\n",
    "        This method allows operates on a Tree object and returns\n",
    "        the MLE PCFG that is generated form the UC CNF from of the\n",
    "        tree.\n",
    "        '''\n",
    "\n",
    "        def recur_bigram_cnt(self, def_dict):\n",
    "            '''\n",
    "            This locally defined method operates on a tree.\n",
    "            It creates the counts for the PCFG recursivly.\n",
    "            After this function is called the probabilites\n",
    "            can be derived from the returned embedded dd.\n",
    "            '''\n",
    "\n",
    "            '''If a daughter is terminal all it is the only daughter\n",
    "            in CNF so store increment the the value with the terminal\n",
    "            string as the key'''\n",
    "\n",
    "\n",
    "            if Tree.terminal(self.daughters[0]):\n",
    "                for d in self.daughters:\n",
    "                    def_dict[self.label][d] += 1.0\n",
    "                return def_dict\n",
    "\n",
    "            else:\n",
    "                dots = tuple(d.label for d in self.daughters)\n",
    "                def_dict[self.label][dots] += 1.0\n",
    "                for d in self.daughters:\n",
    "                    recur_bigram_cnt(d, def_dict)\n",
    "                return def_dict\n",
    "\n",
    "        # 2nd order default dict: data structure to be passed to the function above\n",
    "\n",
    "        def_dict = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "        # call above defined recursive function and store values in dict\n",
    "        recur_bigram_cnt(self, def_dict)\n",
    "\n",
    "        # sum the counts each branch and use that to divide them into probs\n",
    "        for prior in def_dict:\n",
    "            total = sum(def_dict[prior].values())\n",
    "            for term in def_dict[prior]:\n",
    "                def_dict[prior][term] /= total\n",
    "                # print the values\n",
    "                #print(prior,'->', term, def_dict[prior][term])#, total)\n",
    "\n",
    "        # def_dict is now a PCFG for the Tree object\n",
    "        return def_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Class method for stream to PCFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This code should not be run in the notebook. The code\n",
    "here is just a compiled version of my work, seperated form \n",
    "the rest of the code for easy viewing. See how the code is\n",
    "utilized in the following section.'''\n",
    "\n",
    "    @classmethod\n",
    "    def MLE_PCFG_from_stream(cls, handle, modified=False):\n",
    "        '''\n",
    "        This method takes as an input the file name of a .psd\n",
    "        file to generate an MLE PCFG from. the 'modified' \n",
    "        paramater is set to true if it is desired to use the\n",
    "        modified stream to Tree function form assignment 5.\n",
    "        '''\n",
    "\n",
    "\n",
    "        def recur_bigram_cnt(self, def_dict):\n",
    "            '''see implementation notes in the MLE_PCFG function'''\n",
    "\n",
    "            if Tree.terminal(self.daughters[0]):\n",
    "                for d in self.daughters:\n",
    "                    def_dict[self.label][d] += 1.0\n",
    "                return def_dict\n",
    "            else:\n",
    "                dots = tuple(d.label for d in self.daughters)\n",
    "                def_dict[self.label][dots] += 1.0\n",
    "                for d in self.daughters:\n",
    "                    recur_bigram_cnt(d, def_dict)\n",
    "                return def_dict\n",
    "\n",
    "\n",
    "        # declare a dict for results to be stored in\n",
    "        def_dict = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "        # open file stream\n",
    "        with open(handle) as stream:\n",
    "            if modified:\n",
    "                gen = Tree.from_stream_modified(stream)\n",
    "            else:\n",
    "                gen = Tree.from_stream(stream)\n",
    "            for tr in gen:\n",
    "                tr.collapse_unary().chomsky_normal_form()\n",
    "\n",
    "                # call above defined recursive function and store values in dict\n",
    "                recur_bigram_cnt(tr, def_dict)\n",
    "\n",
    "        # sum the counts each branch and use that to divide them into probs\n",
    "        for prior in def_dict:\n",
    "            total = sum(def_dict[prior].values())\n",
    "            for term in def_dict[prior]:\n",
    "                def_dict[prior][term] /= total\n",
    "\n",
    "        return def_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Usage\n",
    "\n",
    "#### 1.2.1 Using the member function for tree to PCFG converstion\n",
    "\n",
    "First we need to generate a tree. We will do so from the string provided with the asignment description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP\n",
      "    (NP\n",
      "        (DT the)\n",
      "        (NN teacher)\n",
      "    )\n",
      "    (VP\n",
      "        (MD will)\n",
      "        (VP\n",
      "            (VB lecture)\n",
      "            (NP\n",
      "                (NN today)\n",
      "                (PP\n",
      "                    (IN in)\n",
      "                    (NP\n",
      "                        (DT the)\n",
      "                        (NN lecture)\n",
      "                        (NN hall)\n",
      "                    )\n",
      "                )\n",
      "            )\n",
      "        )\n",
      "    )\n",
      "    (. .)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# irst we need to generate a tree.\n",
    "tree_string = \"\"\"\n",
    "(TOP\n",
    "    (NP\n",
    "      (DT the)\n",
    "      (NN teacher)\n",
    "    )\n",
    "    (VP\n",
    "      (MD will)\n",
    "      (VP\n",
    "        (VB lecture)\n",
    "        (NP\n",
    "          (NN today)\n",
    "                  (PP\n",
    "          (IN in)\n",
    "          (NP\n",
    "            (DT the)\n",
    "            (NN lecture)\n",
    "            (NN hall)\n",
    "          )\n",
    "        )\n",
    "\n",
    "\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (. .)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "tree_object = tree.Tree.from_string(tree_string)\n",
    "print(tree_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to build the PCFG we can simply call the member function on the tree object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function tree.Tree.MLE_PCFG.<locals>.<lambda>()>,\n",
       "            {'TOP': defaultdict(float, {('NP', 'TOP|<VP&.>'): 1.0}),\n",
       "             'NP': defaultdict(float,\n",
       "                         {('DT', 'NN'): 0.3333333333333333,\n",
       "                          ('NN', 'PP'): 0.3333333333333333,\n",
       "                          ('DT', 'NP|<NN&NN>'): 0.3333333333333333}),\n",
       "             'DT': defaultdict(float, {'the': 1.0}),\n",
       "             'NN': defaultdict(float,\n",
       "                         {'teacher': 0.25,\n",
       "                          'today': 0.25,\n",
       "                          'lecture': 0.25,\n",
       "                          'hall': 0.25}),\n",
       "             'TOP|<VP&.>': defaultdict(float, {('VP', '.'): 1.0}),\n",
       "             'VP': defaultdict(float, {('MD', 'VP'): 0.5, ('VB', 'NP'): 0.5}),\n",
       "             'MD': defaultdict(float, {'will': 1.0}),\n",
       "             'VB': defaultdict(float, {'lecture': 1.0}),\n",
       "             'PP': defaultdict(float, {('IN', 'NP'): 1.0}),\n",
       "             'IN': defaultdict(float, {'in': 1.0}),\n",
       "             'NP|<NN&NN>': defaultdict(float, {('NN', 'NN'): 1.0}),\n",
       "             '.': defaultdict(float, {'.': 1.0})})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCFG_from_treee = tree_object.MLE_PCFG()\n",
    "PCFG_from_treee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2  Using the file stream to PCFG class method\n",
    "\n",
    "Assuming you have access to a file that is formatted in the proper way, it is even easier to use the PCFG from stream class method. The only parameter needed is the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of file\n"
     ]
    }
   ],
   "source": [
    "WSJ_normalized_PCFG = tree.Tree.MLE_PCFG_from_stream('wsj-normalized.psd', modified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `modified` keyword in above tells the system to use the more efficent version of `Tree.from_stream()` that I worte for assignment 5. If it is not set then the original `Tree.from_stream()` will be used. \n",
    "\n",
    "Now we can examine some of results form creating the PCFG from this large of a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {('VP', '.'): 0.9341827625385489,\n",
       "             ('VP', \"TOP|<.&''>\"): 0.062408699886382084,\n",
       "             ('VP', 'TOP|<.&-RRB->'): 0.0033273819185197207,\n",
       "             ('VP', 'TOP|<.&``>'): 8.115565654926148e-05})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSJ_normalized_PCFG['TOP|<VP&.>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'and': 0.7119595732734418,\n",
       "             'but': 0.16591802358225716,\n",
       "             'or': 0.06386861313868614,\n",
       "             '&': 0.046743402582818644,\n",
       "             'nor': 0.0030881527231892197,\n",
       "             'v.': 0.00014037057832678272,\n",
       "             'yet': 0.0022459292532285235,\n",
       "             'both': 0.001403705783267827,\n",
       "             'neither': 0.0007018528916339135,\n",
       "             'either': 0.0016844469399213925,\n",
       "             'plus': 0.0012633352049410444,\n",
       "             'times': 0.00014037057832678272,\n",
       "             \"'n\": 0.00014037057832678272,\n",
       "             'whether': 0.00028074115665356543,\n",
       "             'vs.': 0.0004211117349803481})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSJ_normalized_PCFG['CC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Methodology \n",
    "\n",
    "This it seemed elegant to use extend the tree class rather than build a free standing method. Since the PCFG generations will rely so heavily on the `Tree` class anyway. I am using my own code from assignment number 5 under the possibly false assumption that it is working correctly. \n",
    "\n",
    "For the PCGE gereration, it seemed that recursivly traversing the tree until hitting terminals was the way to go. The data structure used to hold the probabilites is a double embedded default dict. In the recursive iterations a count is incremented at each occourance. After the tree has been traversed across completly, the counts are devided by their totals to make the values represent the probabilities of thier occourance given that higher order nonterminal. \n",
    "\n",
    "### 1.4 Counts\n",
    "\n",
    "To count the total number of rules, we loop through each nonterminal in the grammer and count all the rewrites that can be derived from it. Summing these values together will be the total number of rewrite rules in the grammer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30363"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = 0\n",
    "\n",
    "# loop through each non terminal and count its rules\n",
    "for NT in WSJ_normalized_PCFG:\n",
    "    counts += len(WSJ_normalized_PCFG[NT])\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of total rules: 30,363"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Probabilistic CKY\n",
    "\n",
    "### 2.1 Program\n",
    "\n",
    "The implementation of the Probabalistic CKY algorithm was done with the use of a new class, also sitting in my `tree.py` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This code should not be run in the notebook. The code\n",
    "here is just a compiled version of my work, seperated form \n",
    "the rest of the code for easy viewing. See how the code is\n",
    "utilized in the following section.'''\n",
    "\n",
    "class prob_CKY():\n",
    "\n",
    "    def __init__(self, sentence, grammer):\n",
    "\n",
    "        # localize variables\n",
    "        self.sentence = sentence\n",
    "        self.grammer = grammer\n",
    "\n",
    "        # init word list\n",
    "        self.word_list = sentence.split(' ')\n",
    "        num_words = len(self.word_list)\n",
    "\n",
    "        # declare probability table and backtrace table\n",
    "        self.table = [[defaultdict(float) for i in range(num_words)] for j in range(num_words)]\n",
    "        self.back_trace = [[defaultdict(str) for i in range(num_words)] for j in range(num_words)]\n",
    "\n",
    "        # initalize diagonal of probability table\n",
    "        for diag in range(num_words):\n",
    "            for ctx in grammer:\n",
    "                if grammer[ctx][self.word_list[diag]] > 0:\n",
    "                    self.table[diag][diag][ctx] = grammer[ctx][self.word_list[diag]]\n",
    "                    self.back_trace[diag][diag][ctx] = self.word_list[diag]\n",
    "\n",
    "        # traverse table left to right but up the columns first\n",
    "        for j in range(1,num_words):\n",
    "            for i in reversed(range(j)):\n",
    "\n",
    "                # k will be the offset for examining other branching cells\n",
    "                for k in range(i,j):\n",
    "\n",
    "                    # for every nonterminal in the grammer\n",
    "                    for A in dict(grammer):\n",
    "\n",
    "                        # for every two way branch in  each grammer\n",
    "                        for tup in dict(grammer[A]):\n",
    "                            if type(tup) == tuple and len(tup)==2:\n",
    "                                (B,C) = tup\n",
    "\n",
    "                                #print(self.table[i][k][B], self.table[k][j][C], (i,j,k))\n",
    "                                if self.table[i][k][B] > 0 and self.table[k+1][j][C] > 0:\n",
    "                                    #print('gtz met')\n",
    "                                    #print(self.table[i][k][B], self.table[k+1][j][C], )\n",
    "                                    if self.table[i][j][A] < grammer[A][(B,C)]*self.table[i][k][B]*self.table[k+1][j][C]:\n",
    "                                        #print('conditions met')\n",
    "                                        self.table[i][j][A] = grammer[A][(B,C)]*self.table[i][k][B]*self.table[k+1][j][C]\n",
    "                                        #print(B,C)\n",
    "                                        self.back_trace[i][j][A] = (k+1,(B,C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class constructor takes a string to parse and a grammer in PCFG as inputs. It uses the grammer to generate a memoization array and a backtrace array. After the arrays are created, member functions can be called to actually perform the backtrace and output the parse as a tree. This function is a member function called `to_tree()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This code should not be run in the notebook. The code\n",
    "here is just a compiled version of my work, seperated form \n",
    "the rest of the code for easy viewing. See how the code is\n",
    "utilized in the following section.'''\n",
    "\n",
    "    def parse_successful(self):\n",
    "        num_words = len(self.word_list)\n",
    "        if self.table[0][num_words-1]['TOP'] > 0:\n",
    "            return self.table[0][num_words-1]['TOP']\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def trace_to_tree(self, symbol, position):\n",
    "        #print(back_trace_table)\n",
    "        try:\n",
    "            (k,(B,C)) = self.back_trace[position[0]][position[1]][symbol]\n",
    "            L = self.trace_to_tree(B,(position[0],k-1))\n",
    "            R = self.trace_to_tree(C,(k,position[1]))\n",
    "            parse_tree = Tree(symbol,[L,R])\n",
    "        except:\n",
    "            word = self.back_trace[position[0]][position[1]][symbol]\n",
    "            parse_tree = Tree(symbol,[word])\n",
    "\n",
    "        return parse_tree\n",
    "\n",
    "    def to_tree(self):\n",
    "        size = len(self.back_trace)\n",
    "        parse_tree = self.trace_to_tree('TOP', (0,size-1))\n",
    "        return parse_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above there are three member functions of interest there. The `parse_successful()` function returns the probability of the parse if there is one and returns `False` if a parse is not found. The `trace_to_tree()` function is a helper to the `to_tree()` function for recursive constuction of a parse tree form the backtrace array. Calling `to_tree()` on a `prob_CKY` object will return a `Tree` class object that is the parse of the input sentence.\n",
    "\n",
    "Finally a print function was implemented that outputs the memoization table and/or the backtrace array in an HTML table. This allows for easy viewing of where things are going wrong. I used it to understand the algorithm better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''' This code should not be run in the notebook. The code\n",
    "here is just a compiled version of my work, seperated form \n",
    "the rest of the code for easy viewing. See how the code is\n",
    "utilized in the following section.'''   \n",
    "    \n",
    "    def print_table(self, back = False, only=False):\n",
    "\n",
    "        if not only:\n",
    "            display(HTML(\n",
    "               '<table><tr>{}</tr></table>'.format(\n",
    "                   '</tr><tr>'.join(\n",
    "                       '<td>{}</td>'.format('</td><td>'.join(str(dict(_)) for _ in row)) for row in self.table)\n",
    "                   )\n",
    "            ))\n",
    "\n",
    "        if back:\n",
    "            display(HTML(\n",
    "               '<table><tr>{}</tr></table>'.format(\n",
    "                   '</tr><tr>'.join(\n",
    "                       '<td>{}</td>'.format('</td><td>'.join(str(dict(_)) for _ in row)) for row in self.back_trace)\n",
    "                   )\n",
    "            ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2.2 Usage\n",
    "\n",
    "#### 2.2.1 Usage on small provided example for demonstration of concept\n",
    "\n",
    "Lets demonstrate the functionality on the small example we were provided with. Remember that we currently have `PCFG_from_tree` that we generated from the string `tree_object` which in turn came from `tree_sting`. Lets show these again for the sake of the demonstrateion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TOP\n",
       "    (NP\n",
       "        (DT the)\n",
       "        (NN teacher)\n",
       "    )\n",
       "    (TOP|<VP&.>\n",
       "        (VP\n",
       "            (MD will)\n",
       "            (VP\n",
       "                (VB lecture)\n",
       "                (NP\n",
       "                    (NN today)\n",
       "                    (PP\n",
       "                        (IN in)\n",
       "                        (NP\n",
       "                            (DT the)\n",
       "                            (NP|<NN&NN>\n",
       "                                (NN lecture)\n",
       "                                (NN hall)\n",
       "                            )\n",
       "                        )\n",
       "                    )\n",
       "                )\n",
       "            )\n",
       "        )\n",
       "        (. .)\n",
       "    )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function tree.Tree.MLE_PCFG.<locals>.<lambda>()>,\n",
       "            {'TOP': defaultdict(float, {('NP', 'TOP|<VP&.>'): 1.0}),\n",
       "             'NP': defaultdict(float,\n",
       "                         {('DT', 'NN'): 0.3333333333333333,\n",
       "                          ('NN', 'PP'): 0.3333333333333333,\n",
       "                          ('DT', 'NP|<NN&NN>'): 0.3333333333333333}),\n",
       "             'DT': defaultdict(float, {'the': 1.0}),\n",
       "             'NN': defaultdict(float,\n",
       "                         {'teacher': 0.25,\n",
       "                          'today': 0.25,\n",
       "                          'lecture': 0.25,\n",
       "                          'hall': 0.25}),\n",
       "             'TOP|<VP&.>': defaultdict(float, {('VP', '.'): 1.0}),\n",
       "             'VP': defaultdict(float, {('MD', 'VP'): 0.5, ('VB', 'NP'): 0.5}),\n",
       "             'MD': defaultdict(float, {'will': 1.0}),\n",
       "             'VB': defaultdict(float, {'lecture': 1.0}),\n",
       "             'PP': defaultdict(float, {('IN', 'NP'): 1.0}),\n",
       "             'IN': defaultdict(float, {'in': 1.0}),\n",
       "             'NP|<NN&NN>': defaultdict(float, {('NN', 'NN'): 1.0}),\n",
       "             '.': defaultdict(float, {'.': 1.0})})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCFG_from_treee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have also added a small member function to the `Tree` class that extracts the origional string form the parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the teacher will lecture today in the lecture hall .\n"
     ]
    }
   ],
   "source": [
    "original_string = tree_object.to_string()\n",
    "print(original_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can feed the string and the grammer into the `prob_CKY()` constructor, and test whether it was parsed succesfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.616898148148148e-05"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCKY = tree.prob_CKY(original_string, PCFG_from_treee)\n",
    "PCKY.parse_successful()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that a value was returned from the `parse_successful()` function means that a result was found. We can now have a look at the resulting parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TOP\n",
       "    (NP\n",
       "        (DT the)\n",
       "        (NN teacher)\n",
       "    )\n",
       "    (TOP|<VP&.>\n",
       "        (VP\n",
       "            (MD will)\n",
       "            (VP\n",
       "                (VB lecture)\n",
       "                (NP\n",
       "                    (NN today)\n",
       "                    (PP\n",
       "                        (IN in)\n",
       "                        (NP\n",
       "                            (DT the)\n",
       "                            (NP|<NN&NN>\n",
       "                                (NN lecture)\n",
       "                                (NN hall)\n",
       "                            )\n",
       "                        )\n",
       "                    )\n",
       "                )\n",
       "            )\n",
       "        )\n",
       "        (. .)\n",
       "    )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCKY.to_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the same as our input because the only grammer rules were very specific and forced the sentence back into the shape of the small grammer. \n",
    "\n",
    "Now, using the `print_table()` function we can examine our memoization table and our backtrace table.\n",
    "\n",
    "#### Memoization Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>{'DT': 1.0, 'NP': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.08333333333333333, 'DT': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'TOP': 3.616898148148148e-05}</td></tr><tr><td>{}</td><td>{'NN': 0.25, 'NP|<NN&NN>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NN': 0.0, 'NP|<NN&NN>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NN': 0.0, 'NP|<NN&NN>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NN': 0.0, 'NP|<NN&NN>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NN': 0.0, 'NP|<NN&NN>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NN': 0.0, 'NP|<NN&NN>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NN': 0.0, 'NP|<NN&NN>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NN': 0.0, 'NP|<NN&NN>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NN': 0.0, 'NP|<NN&NN>': 0.0}</td></tr><tr><td>{}</td><td>{}</td><td>{'MD': 1.0, 'PP': 0.0, 'NN': 0.0, 'TOP|<VP&.>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'PP': 0.0, 'NN': 0.0, 'TOP|<VP&.>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'PP': 0.0, 'NN': 0.0, 'TOP|<VP&.>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'PP': 0.0, 'NN': 0.0, 'TOP|<VP&.>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'PP': 0.0, 'NN': 0.0, 'TOP|<VP&.>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'VP': 0.001736111111111111, 'PP': 0.0, 'NN': 0.0, 'TOP|<VP&.>': 0.0, 'NP': 0.0, 'DT': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'VP': 0.00043402777777777775, 'PP': 0.0, 'NN': 0.0, 'TOP|<VP&.>': 0.0, 'NP': 0.0, 'DT': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'TOP|<VP&.>': 0.00043402777777777775, 'PP': 0.0, 'NN': 0.0}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{'NN': 0.25, 'VB': 1.0, 'VP': 0.0, 'NP': 0.0, 'DT': 0.0, 'MD': 0.0, 'IN': 0.0}</td><td>{'NP|<NN&NN>': 0.0625, 'VP': 0.0, 'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'VP': 0.0, 'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'VP': 0.0, 'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'VP': 0.003472222222222222, 'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'VP': 0.0008680555555555555, 'NP': 0.0, 'DT': 0.0, 'NN': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'TOP|<VP&.>': 0.0008680555555555555, 'VP': 0.0}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'NN': 0.25, 'PP': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'PP': 0.0, 'NP': 0.0, 'NN': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'PP': 0.0, 'NP': 0.0, 'NN': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.006944444444444444, 'PP': 0.0, 'NN': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.001736111111111111, 'PP': 0.0, 'NN': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'PP': 0.0, 'NP': 0.0, 'NN': 0.0}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'IN': 1.0, 'PP': 0.0, 'NN': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0}</td><td>{'PP': 0.0, 'NN': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'PP': 0.08333333333333333, 'NN': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'PP': 0.020833333333333332, 'NN': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'PP': 0.0, 'NN': 0.0}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'DT': 1.0, 'NP': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.08333333333333333, 'DT': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.020833333333333332, 'DT': 0.0, 'NN': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NP': 0.0}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'NN': 0.25, 'VB': 1.0, 'NP|<NN&NN>': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'IN': 0.0}</td><td>{'NP|<NN&NN>': 0.0625, 'NN': 0.0, 'NP': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'NN': 0.0, 'NP|<NN&NN>': 0.0}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'NN': 0.25, 'PP': 0.0, 'NP': 0.0, 'TOP|<VP&.>': 0.0, '.': 0.0, 'DT': 0.0, 'VP': 0.0, 'MD': 0.0, 'VB': 0.0, 'IN': 0.0}</td><td>{'PP': 0.0, 'NP': 0.0, 'NN': 0.0, 'TOP|<VP&.>': 0.0, '.': 0.0}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'.': 1.0, 'PP': 0.0, 'NN': 0.0, 'TOP|<VP&.>': 0.0}</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PCKY.print_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtrace Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>{'DT': 'the'}</td><td>{'NP': (1, ('DT', 'NN'))}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'TOP': (2, ('NP', 'TOP|<VP&.>'))}</td></tr><tr><td>{}</td><td>{'NN': 'teacher'}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td></tr><tr><td>{}</td><td>{}</td><td>{'MD': 'will'}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'VP': (3, ('MD', 'VP'))}</td><td>{'VP': (3, ('MD', 'VP'))}</td><td>{'TOP|<VP&.>': (9, ('VP', '.'))}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{'NN': 'lecture', 'VB': 'lecture'}</td><td>{'NP|<NN&NN>': (4, ('NN', 'NN'))}</td><td>{}</td><td>{}</td><td>{'VP': (4, ('VB', 'NP'))}</td><td>{'VP': (4, ('VB', 'NP'))}</td><td>{'TOP|<VP&.>': (9, ('VP', '.'))}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'NN': 'today'}</td><td>{}</td><td>{}</td><td>{'NP': (5, ('NN', 'PP'))}</td><td>{'NP': (5, ('NN', 'PP'))}</td><td>{}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'IN': 'in'}</td><td>{}</td><td>{'PP': (6, ('IN', 'NP'))}</td><td>{'PP': (6, ('IN', 'NP'))}</td><td>{}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'DT': 'the'}</td><td>{'NP': (7, ('DT', 'NN'))}</td><td>{'NP': (7, ('DT', 'NP|<NN&NN>'))}</td><td>{}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'NN': 'lecture', 'VB': 'lecture'}</td><td>{'NP|<NN&NN>': (8, ('NN', 'NN'))}</td><td>{}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'NN': 'hall'}</td><td>{}</td></tr><tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{'.': '.'}</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PCKY.print_table(back=True, only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.2.2 General usage with large grammers\n",
    "\n",
    "Now in the instance we want to use a large grammer to parse a sentence that we do not have a parse for yet, we can do essentially the same exact thing, feeding a larger grammer into the `prob_CKY()` constructor.\n",
    "\n",
    "Remember earlier we created a grammer from the `wsj-normalized.psd` file `WSJ_normalized_PCFG`. Lets use this grammer to build a parse tree for some input sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use this grammer to build a parse tree for some input sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.671988966174452e-17"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string = 'this effort was a great success .'\n",
    "new_CKY = tree.prob_CKY(input_string, WSJ_normalized_PCFG)\n",
    "new_CKY.parse_successful()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our `parse_successful()` function returned a probability, and therfore our parse was a success. Lets perform the backtrace to and get our tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TOP\n",
       "    (NP-SBJ\n",
       "        (DT this)\n",
       "        (NN effort)\n",
       "    )\n",
       "    (TOP|<VP&.>\n",
       "        (VP\n",
       "            (VBD was)\n",
       "            (NP\n",
       "                (DT a)\n",
       "                (NP|<JJ&NN>\n",
       "                    (JJ great)\n",
       "                    (NN success)\n",
       "                )\n",
       "            )\n",
       "        )\n",
       "        (. .)\n",
       "    )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_sentence = new_CKY.to_tree()\n",
    "parsed_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this effort was a great success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3  Methodolgy\n",
    "\n",
    "I found the implementation of the of the CKY algorithm very difficult to understand. I know there are currently some inefficiences in my implementation but I am afraid to alter my seemingly working implementation. I think that these inefficencies come from the fact that the implementation that if followed did not assume the availability of a default dict. In a situation where you are using arrays of objects, it takes the same amount of time to search as it would to itterate over each object in the array and take action on that object if needed. Since dictonaries are hashmaps, implementaion could have possibly been sped up by only searching through the nonterminals contained in the (k,j) and (i,k) indecies, rather than iterating over all of the nonterminals in the vocab.\n",
    "\n",
    "I believe that this distinction causes massive slow downs due to the way a default dict works. Each time an item is queried that does not currently exist in a default dict, it creates an entry for that query and sets it to zero. you can see this demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the default dict\n",
    "the_default_dict = defaultdict(float)\n",
    "the_default_dict['hello'] = 1.11\n",
    "the_default_dict['world']= 2.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the size of the default dict\n",
    "len(the_default_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query for value that does not exist\n",
    "the_default_dict['its me!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice new lenght of default dict\n",
    "len(the_default_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an unneccecary performance darain on our system. It will cost a huge ammount of memory for large grammers since hashmaps are implemented using concecutive memory as far as I know, this is causing massive massive delays for continual resizing. This could be avoided if I did not query the (k,j) and (i,k) indecies of the memoization table for all nonterminals in the grammer, but instead searched each nonterminal for a tuple made up of every combination of values in the (k,j) and (i,k) indecies. \n",
    "\n",
    "### 2.4 Counting successful parses of 'end_of_wsj.txt' using 'bigger_treebank_2.txt' grammer\n",
    "\n",
    "For this section I will need to write some code. The opeartion of the code will be explained in comments within the code. This codeblock can be run from this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1\n",
      "7.604384618538641e-30 0\n",
      "3.955329279632346e-62 0\n",
      "0.0 1\n",
      "0.0 1\n",
      "0.0 1\n",
      "0.0 1\n",
      "0.0 1\n",
      "0.0 1\n",
      "0.0 1\n",
      "2.5410182990623344e-18 0\n",
      "0.0 1\n",
      "3.269638248326755e-48 0\n",
      "0.0 1\n",
      "0.0 1\n",
      "0.0 1\n",
      "0.0 1\n",
      "0.0 1\n",
      "0.0 1\n",
      "0.0 1\n"
     ]
    }
   ],
   "source": [
    "# build the treebaknk grammer\n",
    "TB_grammer = tree.Tree.MLE_PCFG_from_stream('bigger_treebank_2.txt')\n",
    "\n",
    "# use the 'from_stream()' function from the tree class to pull trees from the 'end_of_wsj.txt' file\n",
    "with open('end_of_wsj.txt') as stream:\n",
    "    wsj = tree.Tree.from_stream(stream)\n",
    "    \n",
    "    # for every sample tree in the file\n",
    "    for sample in wsj:\n",
    "        i+=1\n",
    "        # turn the tree into a string\n",
    "        sample_string = sample.to_string()\n",
    "        \n",
    "        # perform Prb_CKY using TB_grammer\n",
    "        cky = tree.prob_CKY(sample_string, TB_grammer)\n",
    "        \n",
    "        # show probabilities and boolean value to be written to file\n",
    "        print(float(cky.parse_successful()), int(not (bool(cky.parse_successful()))))\n",
    "        \n",
    "        # write to file '0' if parse was a success, '1' if parsing failed\n",
    "        with open('end_of_wsj_RESULTS.txt', 'a') as the_file:\n",
    "            the_file.write(str(int(not (bool(cky.parse_successful()))))+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, only 4 of the 21 or so provided trees actually parsed. A file called `end_of_wsj_RESULTS.txt` was written to as requested by the assignment.  It took over half of an hour for this to run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
