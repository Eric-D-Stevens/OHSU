{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 555: Homework 3\n",
    "### Eric Stevens\n",
    "### November 6, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you what use ngrams.py you should use python2\n",
    "# Or, otherwise, you need to modify ngrams.py by yourself in order to use it in python3.\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "from string import punctuation\n",
    "import re\n",
    "import numpy as np\n",
    "from ngrams import ngrams\n",
    "from collections import defaultdict\n",
    "from bitweight import BitWeight, BitWeightRangeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "small_corpus = ['Why dont we start here',\n",
    "                  'Why dont we end there',\n",
    "                  'Let us start with a few other examples',\n",
    "                  'We never start with an example with so few tokens',\n",
    "                  'Tokens can be words that we start with in example docs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZE - converts lists of sentences, like in the small_corpus\n",
    "# to list of list of tokens. All of the other functions will require\n",
    "# their parameters in the form of the outupt of the tokenize function.\n",
    "def tokenize(corpus):\n",
    "    tokens = [sentence.split(' ') for sentence in corpus]\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Language Modeling\n",
    "For this part of the assignment, you will implement two simple count-based n-gram language models: one based on maximum-likelihood estimation, and another based on Witten-Bell smoothing. The data you will be using is a subset of the Penn Treebank's tagged Wall Street Journal articles on which we have done some initial processing. There are two versions of the data for this assignment:\n",
    "\n",
    "##### wsj.pos.gz\n",
    "##### wsj-normalized.pos.gz\n",
    "The difference is that, in the second (normalized) version of the data, we have collapsed some entries from certain tag categories (e.g. CDs, NNPs, etc.) into type-tokens to help reduce sparsity. Take a look at the data and see for yourself. Consider: what would be the benefits and drawbacks to this method of sparsity reduction? Note that, for this part of the assignment, the tags are un-necessary, so you'll want to work with the un-normalized version of the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: produce a tag-free corpus\n",
    "\n",
    "For this task, you have two jobs. \n",
    "* First, you need to write a function to filter out all tags. \n",
    "* Second, Make sure your code works for both wsj.pos.gz and wsj-normalized.pos.gz\n",
    "\n",
    "####What to turn in\n",
    "* your code\n",
    "* some samples to show me that your code works as it should be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Filter for 'wsj.pos' and 'wsj-normalized.pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FILE_TO_LIST - turns the wsj files into the form of the 'small_corpus'\n",
    "# to prepare it to be the input parameter of the 'tokenize()' function.\n",
    "def file_to_list(filename):\n",
    "    with open(filename, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "        no_tags = re.sub('(<[A-Z$]{2,4}>)|(/[A-Z$]{2,4})|(\\.\\s+[a-z])|(/[,$])|[\\\\,/\\'`]', '', content)\n",
    "        return re.split('\\.\\.|[\\n]',no_tags)\n",
    "    \n",
    "# NOTE: This function assumes that 'wsj.pos' and 'wsj-normalised.pos' have been unzipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate Filtering On 'wsj.pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Digital Equipment Corp. reported a 32 % decline in net income on a modest revenue gain in its fiscal first quarter  causing some analysts to predict weaker results ahead than they had expected ',\n",
       " u'',\n",
       " u'Although the second-largest computer maker had prepared Wall Street for a poor quarter  analysts said they were troubled by signs of flat U.S. orders and a slowdown in the rate of gain in foreign orders ',\n",
       " u' The Maynard  Mass.  company is in a transition in which it is trying to reduce its reliance on mid-range machines and establish a presence in workstations and mainframes ',\n",
       " u'',\n",
       " u'Net for the quarter ended Sept. 30 fell to $ 150.8 million  or $ 1.20 a share  from $ 223 million  or $ 1.71 a share  a year ago ',\n",
       " u' Revenue rose 6.4 % to $ 3.13 billion from $ 2.94 billion ',\n",
       " u'',\n",
       " u'Digital said a shift in its product mix toward low-end products and strong growth in workstation sales yielded lower gross margins ',\n",
       " u' A spokesman also said margins for the company s service business narrowed somewhat because of heavy investments made in that sector ']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 values of 'wsj.pos'\n",
    "wsj_filtered = file_to_list('wsj.pos')\n",
    "wsj_filtered[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate Filtering On 'wsj-normalized.pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'   reported a  % decline in net income on a modest revenue gain in its fiscal first quarter  causing some analysts to predict weaker results ahead than they had expected ',\n",
       " u'',\n",
       " u'Although the second-largest computer maker had prepared   for a poor quarter  analysts said they were troubled by signs of flat  orders and a slowdown in the rate of gain in foreign orders ',\n",
       " u' The     company is in a transition in which it is trying to reduce its reliance on mid-range machines and establish a presence in workstations and mainframes ',\n",
       " u'',\n",
       " u'Net for the quarter ended   fell to $    or $  a share  from $    or $  a share  a year ago ',\n",
       " u' Revenue rose  % to $   from $   ',\n",
       " u'',\n",
       " u'Digital said a shift in its product mix toward low-end products and strong growth in workstation sales yielded lower gross margins ',\n",
       " u' A spokesman also said margins for the company s service business narrowed somewhat because of heavy investments made in that sector ']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 values of 'wsj-normalized.pos'\n",
    "wsj_normalized_filtered = file_to_list('wsj-normalized.pos')\n",
    "wsj_normalized_filtered[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Self assessment:</font>\n",
    "\n",
    "This section could have been done better. I was working under the assumption that with 10 MB of data, paying attention to things like the upper/lower case of the letters would not be important. I also did not remove all punctuation. I tried many combinations of of splitting the data. The assignment description does not explicitly state how any of these things should be done, only that the POS tags should be removed. So, although I think I could have done things better, I do believe that I followed the assignment instructions and should not be marked down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood\n",
    "Now, start by producing code to compute maximum-likelihood estimate probabilities. Your code should be configurable with respect to the n-gram order- i.e., you should be able to set it to compute bigram, trigram, 4-gram, etc. probabilities. Refer to J&M and the lecture slides for definitions as needed. If you would like to write your own n-gram tokenization code, feel free to do so, but you may also use the ngrams.py utility class which contains a routine to take a list of tokens and produce a stream of n-grams with appropriate padding for the start and end of sentences.\n",
    "\n",
    "#### Tip: \n",
    "* Start with a very small \"toy\" corpus of just a couple of sentences for debugging. \n",
    "\n",
    "* As discussed in class, I strongly recommend using nested defaultdicts as the foundational data structure for your language model, where the \"outer\" key is the prefix, and the value retrieved by that prefix is a second defaultdict  containing possible suffices for that prefix, each of which is an \"inner\" key. E.g., p(\"TRUTHS\" | \"HOLD THESE\") would be retrieved by first looking up \"HOLD THESE\" and then from the resulting dictionary, looking up \"TRUTHS\": prob = trigrams[(\"HOLD\",\"THESE\")][\"TRUTHS\"] . Note that this arrangement makes it very easy to e.g. find out the number of times a given history occurs, the total probability mass assigned to all of a history's continuations, etc., all of which will be extremely helpful in the next part of the assignment.\n",
    "\n",
    "* Use tuples to represent prefixes. E.g., instead of the string \"HOLD THESE\", use the tuple (\"HOLD\", \"THESE\"). Note that, in Python, lists are mutable, and therefore may not be used as keys in dictionaries- but tuples are immutable, and so make excellent keys.\n",
    "\n",
    "* Don't forget about numerical underflow issues! You'll want to represent probabilities as negative base-2 log probabilities, and modify your arithmetic accordingly. I recommend experimenting with [the bitweight Python library](https://github.com/stevenbedrick/bitweight) (see its unit tests for example usage).\n",
    "* \n",
    "\n",
    "#### What to turn in:\n",
    "* your code \n",
    "* use your code to create a simple language model for small_corpus named as small_lm and show me that your output is correct(This is a small coupus so you could manully calculate the probalility).\n",
    "* use your code to create language model for wsj.pos.gz named as wsj_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Counting, Maximum Likelihood and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZE - converts lists of sentences, like in the small_corpus\n",
    "# to list of list of tokens. All of the other functions will require\n",
    "# their parameters in the form of the outupt of the tokenize function.\n",
    "def tokenize(corpus):\n",
    "    tokens = [sentence.split(' ') for sentence in corpus]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# COUNT_BUILDER - generates count models where 'corpus' is in \n",
    "# the form output by 'tokenize()'. Order is the 'n' in n-gram.\n",
    "def count_builder(corpus, order):\n",
    "    \n",
    "    #ngram\n",
    "    ng = ngrams(corpus, order)\n",
    "\n",
    "    # describe model datatype\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    \n",
    "    # loop to build embedded defaultdict    \n",
    "    for gram in ng: \n",
    "        if not gram[1] in model[gram[0]]:\n",
    "            model[gram[0]][gram[1]] = 1\n",
    "        else:\n",
    "            model[gram[0]][gram[1]] += 1\n",
    "\n",
    "    # Count Model\n",
    "    return model\n",
    "\n",
    "\n",
    "# MAX_LIKELIHOOD - converts a count model into its MLE form.\n",
    "# 'count_model' is in the form output by 'count_builder()'\n",
    "def max_likelihood(count_model):\n",
    "    \n",
    "    # Container for MLE model with BitWeight probabilities\n",
    "    # Returns 0 for unseen values.\n",
    "    model = defaultdict(lambda: defaultdict(lambda: BitWeight(0)))\n",
    "    \n",
    "    # for prefixes in model...\n",
    "    for prefix, suffix_dict in count_model.iteritems():\n",
    "        w_minus = BitWeight(0) # used to count total tokens\n",
    "        \n",
    "        # for words with hist prefix ...\n",
    "        for suffix, count in suffix_dict.iteritems():\n",
    "            w_minus += BitWeight(count) # add to total number of tokens\n",
    "        \n",
    "        # again, for words with hist prefix ...\n",
    "        for suffix, count in suffix_dict.iteritems():\n",
    "            model[prefix][suffix] = BitWeight.__itruediv__(BitWeight(count),w_minus) # set output probabilities\n",
    "    \n",
    "    # MLE Probabilities\n",
    "    return model\n",
    "\n",
    "\n",
    "# MODEL_PRINTER: Utility to print models with 'BitWeight' values\n",
    "def model_printer(model):\n",
    "    for prefix, suffix_dict in model.iteritems():\n",
    "        for suffix, value in suffix_dict.iteritems():\n",
    "            print(prefix, \" : \", suffix, \" : \", value.real())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate MLE Model Build on 'small_corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'examples',)  :  </S_0>  :  1.0\n",
      "(u'few',)  :  tokens  :  0.5\n",
      "(u'few',)  :  other  :  0.5\n",
      "(u'in',)  :  example  :  1.0\n",
      "(u'We',)  :  never  :  1.0\n",
      "(u'Why',)  :  dont  :  1.0\n",
      "(u'end',)  :  there  :  1.0\n",
      "(u'start',)  :  with  :  0.75\n",
      "(u'start',)  :  here  :  0.25\n",
      "(u'other',)  :  examples  :  1.0\n",
      "(u'here',)  :  </S_0>  :  1.0\n",
      "(u'words',)  :  that  :  1.0\n",
      "(u'an',)  :  example  :  1.0\n",
      "(u'we',)  :  start  :  0.666666666667\n",
      "(u'we',)  :  end  :  0.333333333333\n",
      "(u'dont',)  :  we  :  1.0\n",
      "(u'there',)  :  </S_0>  :  1.0\n",
      "('<S_0>',)  :  Tokens  :  0.2\n",
      "('<S_0>',)  :  We  :  0.2\n",
      "('<S_0>',)  :  Let  :  0.2\n",
      "('<S_0>',)  :  Why  :  0.4\n",
      "(u'so',)  :  few  :  1.0\n",
      "(u'us',)  :  start  :  1.0\n",
      "(u'a',)  :  few  :  1.0\n",
      "(u'example',)  :  docs  :  0.5\n",
      "(u'example',)  :  with  :  0.5\n",
      "(u'docs',)  :  </S_0>  :  1.0\n",
      "(u'Tokens',)  :  can  :  1.0\n",
      "(u'never',)  :  start  :  1.0\n",
      "(u'Let',)  :  us  :  1.0\n",
      "(u'can',)  :  be  :  1.0\n",
      "(u'be',)  :  words  :  1.0\n",
      "(u'with',)  :  a  :  0.25\n",
      "(u'with',)  :  an  :  0.25\n",
      "(u'with',)  :  so  :  0.25\n",
      "(u'with',)  :  in  :  0.25\n",
      "(u'tokens',)  :  </S_0>  :  1.0\n",
      "(u'that',)  :  we  :  1.0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a trigram MLE language model for 'small_corpus' and show result\n",
    "small_tokens = tokenize(small_corpus)\n",
    "small_count = count_builder(small_tokens, 2)\n",
    "small_lm = max_likelihood(small_count)\n",
    "model_printer(small_lm)\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate MLE Model Build on 'wsj.pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'have', u'made')  :    :  0.0434782608696\n",
      "(u'have', u'made')  :  some  :  0.0434782608696\n",
      "(u'have', u'made')  :  it  :  0.130434782609\n",
      "(u'have', u'made')  :  trading  :  0.0217391304348\n",
      "(u'have', u'made')  :  use  :  0.0434782608696\n",
      "(u'have', u'made')  :  for  :  0.0217391304348\n",
      "(u'have', u'made')  :  no  :  0.0652173913043\n",
      "(u'have', u'made')  :  leveraged  :  0.0217391304348\n",
      "(u'have', u'made')  :  their  :  0.0434782608696\n",
      "(u'have', u'made')  :  much  :  0.0217391304348\n",
      "(u'have', u'made')  :  China  :  0.0217391304348\n",
      "(u'have', u'made')  :  health  :  0.0217391304348\n",
      "(u'have', u'made')  :  available  :  0.0217391304348\n",
      "(u'have', u'made')  :  them  :  0.0217391304348\n",
      "(u'have', u'made')  :  his  :  0.0217391304348\n",
      "(u'have', u'made')  :  big  :  0.0217391304348\n",
      "(u'have', u'made')  :  metrics  :  0.0217391304348\n",
      "(u'have', u'made')  :  nearly  :  0.0217391304348\n",
      "(u'have', u'made')  :  excellent  :  0.0217391304348\n",
      "(u'have', u'made')  :  such  :  0.0217391304348\n",
      "(u'have', u'made')  :  him  :  0.0217391304348\n",
      "(u'have', u'made')  :  a  :  0.152173913043\n",
      "(u'have', u'made')  :  the  :  0.152173913043\n",
      "(u'love', u'--:')  :  and  :  1.0\n",
      "(u'webs', u'of')  :  cross-shareholdings  :  1.0\n",
      "(u'a', u'picture-postcard')  :  vista  :  1.0\n",
      "(u'on', u'atmospheric')  :  pollution  :  1.0\n",
      "(u'strike', u'last')  :  month  :  1.0\n",
      "(u'selloff', u'followed')  :  by  :  1.0\n",
      "(u'small', u'account')  :    :  1.0\n",
      "(u'Partly', u'because')  :  of  :  0.75\n",
      "(u'Partly', u'because')  :  the  :  0.25\n",
      "(u'Chicago', u'businessman')  :  William  :  0.5\n",
      "(u'Chicago', u'businessman')  :  Sam  :  0.5\n"
     ]
    }
   ],
   "source": [
    "# Create trigram MLE language model for 'wsj.pos' and show subset\n",
    "wsj_tokens = tokenize(wsj_filtered)\n",
    "wsj_count = count_builder(wsj_tokens, 3)\n",
    "wsj_lm = max_likelihood(wsj_count)\n",
    "\n",
    "# grab 10 keys\n",
    "top_keys = wsj_lm.keys()[:10]\n",
    "\n",
    "# subset of language model\n",
    "sub_wsj = defaultdict(lambda: defaultdict(lambda: BitWeight(0)))\n",
    "for key in top_keys: sub_wsj[key] = wsj_lm[key]\n",
    "                      \n",
    "# print subsample of wsj_model\n",
    "model_printer(sub_wsj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Self assessment:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing\n",
    "\n",
    "Once you’ve got an unsmoothed model working, move on to implementing Witten-Bell smoothing. Refer to the slides and J&M for details on how that ought to work.\n",
    "\n",
    "#### Tip: \n",
    "* You can modify an already-populated defaultdict to change its default value (for example, to store a default backoff value for a particular history) by changing the object’s default_factory attribute. Consult the documentation for examples of how this works.\n",
    "* As defined, W-B smoothing is highly recursive; you may find it more efficient to re-frame the algorithm in iterative terms.\n",
    "* As in the previous section, start small.\n",
    "* [This may offer you some help on how to implement Witten-Bell smoothing](http://www.ee.columbia.edu/~stanchen/e6884/labs/lab3/x207.html)\n",
    "\n",
    "\n",
    "#### What to turn in:\n",
    "* your code \n",
    "* use your code to create a simple smoothed language model based on small_lm  and show me that your output is correct(This is a small coupus so you could manully calculate the probalility).\n",
    "* use your code to create a smoothed language model based on wsj_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whitten-Bell Ngram Model Builder Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build list of counts from order of grams\n",
    "def count_list_builder(corpus, order):\n",
    "    \n",
    "    # holds count models of each order\n",
    "    count_list = []\n",
    "    \n",
    "    # tokenize the corpus\n",
    "    tokens = tokenize(corpus)\n",
    "    \n",
    "    # for each order, add count model to count list\n",
    "    for n in range(order):\n",
    "        count_list.append(count_builder(tokens, n+1))\n",
    "        \n",
    "    # return the count list for use in the calc wb function\n",
    "    return count_list\n",
    "    \n",
    "# take input list of counts and calculate wb\n",
    "def calculate_wb(prefix, suffix, count_list):\n",
    "    \n",
    "    # unigram calculations\n",
    "    ch = BitWeight(sum(count_list[0][()].values()))\n",
    "    N_one = BitWeight(len(count_list[0][()].keys()))\n",
    "    lam = BitWeight.__truediv__(ch,(ch+N_one))\n",
    "    one_min_lam = BitWeight.__truediv__(N_one,(ch+N_one))\n",
    "    \n",
    "    # unigram maximum likelihood\n",
    "    Pmle = BitWeight.__truediv__(BitWeight(count_list[0][()][suffix]), ch)\n",
    "    \n",
    "    # unigram witten bell probability\n",
    "    pb = (lam * Pmle) + BitWeight.__truediv__(BitWeight(1),(ch+N_one))\n",
    "\n",
    "    \n",
    "    # if order is greater than 1 get values from other \n",
    "    for x in range(1,len(prefix)):\n",
    "        \n",
    "        ch = BitWeight(sum(count_list[x][prefix[-x:]].values()))\n",
    "        N_one = BitWeight(len(count_list[x][prefix[-x:]].keys()))\n",
    "\n",
    "        lam = BitWeight.__truediv__(ch,(ch+N_one))\n",
    "        one_min_lam = BitWeight.__truediv__(N_one,(ch+N_one))\n",
    "        \n",
    "        Pmle = BitWeight.__truediv__(BitWeight(count_list[x][prefix[-x:]][suffix]), ch)\n",
    "        \n",
    "        pb += (lam*Pmle) + (one_min_lam*pb)\n",
    "    \n",
    "    return pb\n",
    "\n",
    "def wb_model_builder(corpus, order):\n",
    "    wb_model = defaultdict(lambda: defaultdict(lambda: BitWeight))\n",
    "    counts = count_list_builder(corpus, order)\n",
    "    for prefix, suffix_dict in counts[len(counts)-1].iteritems():\n",
    "        for suffix, value in suffix_dict.iteritems():\n",
    "            wb_model[prefix][suffix] = calculate_wb(prefix,suffix,counts)\n",
    "    return wb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bitweight.BitWeight at 0x125186720>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_wb((),\"limited\",x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate WB Model Build on 'small_corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'us', u'start')  :  with  :  0.60101010101\n",
      "(u'few', u'other')  :  examples  :  0.545454545455\n",
      "(u'start', u'with')  :  a  :  0.170454545455\n",
      "(u'start', u'with')  :  an  :  0.170454545455\n",
      "(u'start', u'with')  :  in  :  0.170454545455\n",
      "('<S_1>', u'We')  :  never  :  0.544117647059\n",
      "('<S_0>', '<S_1>')  :  Tokens  :  0.0597014925373\n",
      "('<S_0>', '<S_1>')  :  We  :  0.0597014925373\n",
      "('<S_0>', '<S_1>')  :  Let  :  0.0597014925373\n",
      "('<S_0>', '<S_1>')  :  Why  :  0.089552238806\n",
      "(u'start', u'here')  :  </S_1>  :  0.0223880597015\n",
      "(u'Let', u'us')  :  start  :  0.610294117647\n",
      "(u'that', u'we')  :  start  :  0.502941176471\n",
      "(u'example', u'with')  :  so  :  0.169117647059\n",
      "(u'example', u'docs')  :  </S_1>  :  0.0220588235294\n",
      "(u'in', u'example')  :  docs  :  0.294117647059\n",
      "(u'we', u'end')  :  there  :  0.544117647059\n",
      "(u'a', u'few')  :  other  :  0.294117647059\n",
      "(u'with', u'an')  :  example  :  0.566176470588\n",
      "(u'with', u'so')  :  few  :  0.566176470588\n",
      "(u'words', u'that')  :  we  :  0.588235294118\n",
      "(u'end', u'there')  :  </S_1>  :  0.0220588235294\n",
      "(u'other', u'examples')  :  </S_1>  :  0.0220588235294\n",
      "(u'dont', u'we')  :  start  :  0.502941176471\n",
      "(u'dont', u'we')  :  end  :  0.241176470588\n",
      "('<S_1>', u'Let')  :  us  :  0.544117647059\n",
      "(u'never', u'start')  :  with  :  0.599502487562\n",
      "(u'can', u'be')  :  words  :  0.544117647059\n",
      "(u'docs', '</S_1>')  :  </S_0>  :  0.030303030303\n",
      "('<S_1>', u'Tokens')  :  can  :  0.544117647059\n",
      "(u'there', '</S_1>')  :  </S_0>  :  0.0294117647059\n",
      "(u'with', u'a')  :  few  :  0.566176470588\n",
      "(u'so', u'few')  :  tokens  :  0.294117647059\n",
      "(u'here', '</S_1>')  :  </S_0>  :  0.0294117647059\n",
      "(u'Why', u'dont')  :  we  :  0.745098039216\n",
      "(u'be', u'words')  :  that  :  0.544117647059\n",
      "(u'examples', '</S_1>')  :  </S_0>  :  0.0294117647059\n",
      "(u'with', u'in')  :  example  :  0.566176470588\n",
      "(u'We', u'never')  :  start  :  0.610294117647\n",
      "(u'tokens', '</S_1>')  :  </S_0>  :  0.0294117647059\n",
      "(u'an', u'example')  :  with  :  0.360294117647\n",
      "('<S_1>', u'Why')  :  dont  :  0.725490196078\n",
      "(u'Tokens', u'can')  :  be  :  0.544117647059\n",
      "(u'few', u'tokens')  :  </S_1>  :  0.0220588235294\n",
      "(u'we', u'start')  :  with  :  0.598039215686\n",
      "(u'we', u'start')  :  here  :  0.205882352941\n"
     ]
    }
   ],
   "source": [
    "# Create a trigram Witten-Bell language model for 'small_corpus' and show result\n",
    "small_wb_lm = wb_model_builder(small_corpus, 3)\n",
    "model_printer(small_wb_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate WB Model Build on 'wsj.pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'10.1',)  :  %  :  0.00391575299097\n",
      "(u'resolve',)  :  problems  :  0.000316592795014\n",
      "(u'frequent',)  :  flier  :  3.33255573699e-05\n",
      "(u'frequent',)  :  junkets  :  3.33255573699e-05\n",
      "(u'Unless',)  :  the  :  0.0363075897692\n",
      "(u'Signal',)  :    :  0.12240477222\n",
      "(u'Signal',)  :  stock-quote  :  3.33255573699e-05\n",
      "(u'grueling',)  :  period  :  0.000316592795014\n",
      "(u'two-income',)  :  couple  :  0.00026660445896\n",
      "(u'two-income',)  :  family  :  0.00019995334422\n",
      "(u'Scania',)  :  truck  :  0.000149965008165\n",
      "(u'fraudulent',)  :  telemarketing  :  6.66511147399e-05\n",
      "(u'transportation',)  :    :  0.12240477222\n",
      "(u'transportation',)  :  logistics  :  4.99883360549e-05\n",
      "(u'transportation',)  :  1230.80  :  3.33255573699e-05\n",
      "(u'transportation',)  :  deregulation  :  8.33138934249e-05\n",
      "(u'transportation',)  :  system  :  0.000349918352384\n",
      "(u'transportation',)  :  etc  :  3.33255573699e-05\n",
      "(u'transportation',)  :  rates  :  0.000899790048989\n",
      "(u'transportation',)  :  at  :  0.00401572966308\n",
      "(u'40-a-share',)  :  proposal  :  0.000149965008165\n",
      "(u'ending',)  :  a  :  0.01697937148\n",
      "(u'80',)  :  to  :  0.0197453927417\n",
      "(u'80',)  :  million  :  0.00278268404039\n",
      "(u'80',)  :  yen  :  0.00013330222948\n",
      "(u'now',)  :    :  0.12240477222\n",
      "(u'now',)  :  because  :  0.00108308061452\n",
      "(u'now',)  :  being  :  0.000483220581864\n",
      "(u'now',)  :  is  :  0.00581530976106\n",
      "(u'now',)  :  influence  :  0.000116639450795\n",
      "(u'now',)  :  an  :  0.00298263738461\n",
      "(u'now',)  :  bring  :  6.66511147399e-05\n",
      "(u'now',)  :  accounts  :  0.00016662778685\n",
      "(u'now',)  :  are  :  0.00394907854834\n",
      "(u'now',)  :  have  :  0.00283267237645\n",
      "(u'now',)  :  need  :  0.000349918352384\n",
      "(u'now',)  :  if  :  0.000916452827674\n",
      "(u'now',)  :  appear  :  4.99883360549e-05\n",
      "(u'now',)  :  get  :  0.000633185590029\n",
      "(u'now',)  :  40  :  0.00026660445896\n",
      "(u'now',)  :  to  :  0.0197453927417\n",
      "(u'now',)  :  goes  :  0.000149965008165\n",
      "(u'now',)  :  equaling  :  3.33255573699e-05\n",
      "(u'now',)  :  that  :  0.00794814543273\n",
      "(u'now',)  :  ?.  :  0.000483220581864\n",
      "(u'now',)  :  part  :  0.000366581131069\n",
      "(u'now',)  :  focused  :  3.33255573699e-05\n",
      "(u'now',)  :  nearly  :  0.000216616122905\n",
      "(u'now',)  :  using  :  0.000116639450795\n",
      "(u'now',)  :  strike  :  4.99883360549e-05\n",
      "(u'now',)  :  holds  :  8.33138934249e-05\n",
      "(u'now',)  :  must  :  0.000449895024494\n",
      "(u'now',)  :  on  :  0.0044322991302\n",
      "(u'now',)  :  works  :  6.66511147399e-05\n",
      "(u'now',)  :  calls  :  0.00016662778685\n",
      "(u'now',)  :  trading  :  0.000666511147399\n",
      "(u'now',)  :  retail  :  9.99766721098e-05\n",
      "(u'now',)  :  makes  :  0.00023327890159\n",
      "(u'now',)  :  think  :  0.000366581131069\n",
      "(u'Again',)  :    :  0.12240477222\n",
      "(u'top-rated',)  :  education  :  9.99766721098e-05\n",
      "(u'career',)  :  advice  :  8.33138934249e-05\n",
      "(u'career',)  :  that  :  0.00794814543273\n",
      "(u'everyone',)  :  I  :  0.0015496384177\n",
      "(u'everyone',)  :  is  :  0.00581530976106\n",
      "(u'everyone',)  :  who  :  0.00209951011431\n",
      "(u'everyone',)  :  believes  :  0.00019995334422\n",
      "(u'mainframe-class',)  :  computers  :  0.000283267237645\n",
      "(u'publicity',)  :  about  :  0.00191618761976\n",
      "(u'thwarted',)  :  by  :  0.00368247408938\n",
      "(u'476.5',)  :  million  :  0.00278268404039\n",
      "(u'rate',)  :    :  0.12240477222\n",
      "(u'rate',)  :  and  :  0.0131802579398\n",
      "(u'rate',)  :  for  :  0.00746492485087\n",
      "(u'rate',)  :  of  :  0.0210284267004\n",
      "(u'rate',)  :  in  :  0.0134968507348\n",
      "(u'rate',)  :  it  :  0.00356583463858\n",
      "(u'rate',)  :  increase  :  0.000566534475289\n",
      "(u'rate',)  :  also  :  0.00141633618822\n",
      "(u'rate',)  :  increases  :  0.000333255573699\n",
      "(u'rate',)  :  discounting  :  0.00013330222948\n",
      "(u'rate',)  :  will  :  0.00246609124538\n",
      "(u'rate',)  :  weakness  :  6.66511147399e-05\n",
      "(u'rate',)  :  prevail  :  3.33255573699e-05\n",
      "(u'rate',)  :  historically  :  3.33255573699e-05\n",
      "(u'projected',)  :  lower  :  0.000449887528118\n",
      "(u'projected',)  :  cash  :  0.000483212530201\n",
      "(u'films',)  :  or  :  0.00304923769058\n",
      "(u'tax-compliance',)  :  material  :  4.99883360549e-05\n",
      "(u'240',)  :  a  :  0.01697937148\n",
      "(u'revolutionary',)  :  system  :  0.000349918352384\n",
      "(u'69-26',)  :  Friday  :  0.000699836704769\n",
      "(u'offset',)  :  high  :  0.000533208917919\n",
      "(u'offset',)  :  loss  :  0.00026660445896\n",
      "(u'offset',)  :  sluggish  :  4.99883360549e-05\n",
      "(u'offset',)  :  by  :  0.00368247408938\n",
      "(u'offset',)  :  her  :  0.000216616122905\n",
      "(u'busy',)  :  for  :  0.00746492485087\n",
      "(u'staggering',)  :  46  :  3.33255573699e-05\n",
      "(u'waited',)  :  until  :  0.00026660445896\n",
      "(u'proessional',)  :  hesitate  :  4.99883360549e-05\n",
      "(u'Electric',)  :  plant  :  0.000183290565535\n",
      "(u'Electric',)  :  Co.  :  0.000599860032659\n",
      "(u'trimmed',)  :  their  :  0.00206618455694\n",
      "(u'trimmed',)  :  demand  :  0.00029993001633\n",
      "(u'Hasbro',)  :  gained  :  0.00026660445896\n",
      "(u'appealed',)  :  to  :  0.0197453927417\n",
      "(u'created',)  :  even  :  0.000633185590029\n",
      "(u'created',)  :  in  :  0.0134968507348\n",
      "(u'NBC',)  :  News  :  4.99883360549e-05\n",
      "(u'implemented',)  :  last  :  0.00111640617189\n",
      "(u'mid-October',)  :  auto  :  0.000149965008165\n",
      "(u'stockholdings',)  :  involve  :  6.66511147399e-05\n",
      "(u'stockholdings',)  :    :  0.12240477222\n",
      "(u'declared',)  :    :  0.12240477222\n",
      "(u'declared',)  :  bankrupt  :  3.33255573699e-05\n",
      "(u'2679.72',)  :    :  0.12240477222\n",
      "(u'trustee',)  :    :  0.12240477222\n",
      "(u'later',)  :    :  0.12240477222\n",
      "(u'later',)  :  adding  :  0.000116639450795\n",
      "(u'later',)  :  shown  :  3.33255573699e-05\n",
      "(u'later',)  :  --:  :  0.0019995334422\n",
      "(u'later',)  :  next  :  0.000416569467124\n",
      "(u'later',)  :  conceded  :  8.33138934249e-05\n",
      "(u'later',)  :  than  :  0.00173292898324\n",
      "(u'Cammack',)  :    :  0.12240477222\n",
      "(u'responds',)  :  ::  :  0.00101642949978\n",
      "(u'short-changing',)  :  the  :  0.0363081947546\n"
     ]
    }
   ],
   "source": [
    "# Create trigram Witten-Bell language model for 'wsj.pos' and show subset\n",
    "wsj_wb_lm = wb_model_builder(tl[:3000], 2)\n",
    "\n",
    "# grab 10 keys\n",
    "top_keys = wsj_wb_lm.keys()[:50]\n",
    "\n",
    "# subset of language model\n",
    "sub_wsj_wb = defaultdict(lambda: defaultdict(lambda: BitWeight(0)))\n",
    "for key in top_keys: sub_wsj_wb[key] = wsj_wb_lm[key]\n",
    "                      \n",
    "# print subsample of wsj_wb_model\n",
    "model_printer(sub_wsj_wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Self assessment:</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contained many mistakes and I have still not fully resolved these issues. My solution didn't take into account the fact that the `ngram()` function returned a less than ideal form. When using the function, the return is in the from `<S_0><S_1><S_2>...</S_2><S_1></S_0>`. This results in every single sentence having multiple unseen grams. If we reverse the ordering of the padding to `<S_2><S_1><S_0>...</S_0><S_1></S_2>` then we drastically reduce this problem and only have a single unseen word per sentence, `(</S_1>)|<S_2>` in this case. This can be done by modifying the ngram code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    left_pad = ['<S_{}>'.format((order-1)-i) for i in xrange(order - 1)] \n",
    "    right_pad = ['</S_{}>'.format((order-1)-i) for i in xrange(order - 2, -1, -1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next major mistake, which resulted in a perplexity jump from 1 to 2 gram was in line 33:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # if order is greater than 1 get values from other \n",
    "    for x in range(1,len(prefix)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line caused early termination of the $P_wb$ calculation. The result was that what we thought was a trigram was actually a bigram calculation and what we thought was the 4gram was actually the trigram calculation. For the bigram calculation, it was bigger than the unigram because it was basically counting the whole bigram as if it were a unigram. So the number of calculations was bigger but they were all being evaluated as unigram probabilities. This bug was resolved by changing the code to access the intended order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # if order is greater than 1 get values from other \n",
    "    for x in range(1,len(prefix)+1):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I went back and read how the algorithm works realized that there is supposed to be a cutoff when there is a 0 history count. In my submission I allowed calculations up through the order of the smoothing. In order to change this to be consistent with taking the previous $P_wb$ directly after finding a 0 history count I changed the following lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for x in range(1,len(prefix)):\n",
    "\n",
    "        ch = BitWeight(sum(count_list[x][prefix[-x:]].values()))\n",
    "        N_one = BitWeight(len(count_list[x][prefix[-x:]].keys()))\n",
    "\n",
    "        lam = BitWeight.__truediv__(ch,(ch+N_one))\n",
    "        one_min_lam = BitWeight.__truediv__(N_one,(ch+N_one))\n",
    "        \n",
    "        Pmle = BitWeight.__truediv__(BitWeight(count_list[x][prefix[-x:]][suffix]), ch)\n",
    "        \n",
    "        pb += (lam*Pmle) + (one_min_lam*pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addition of a return statement on the occouranc of a 0 history count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for x in range(1,len(prefix)):\n",
    "        \n",
    "        if(len(count_list[x][prefix[-x:]].keys()) == 0):\n",
    "            return pb\n",
    "        \n",
    "        ch = BitWeight(sum(count_list[x][prefix[-x:]].values()))\n",
    "        N_one = BitWeight(len(count_list[x][prefix[-x:]].keys()))\n",
    "\n",
    "        lam = BitWeight.__truediv__(ch,(ch+N_one))\n",
    "        one_min_lam = BitWeight.__truediv__(N_one,(ch+N_one))\n",
    "        \n",
    "        Pmle = BitWeight.__truediv__(BitWeight(count_list[x][prefix[-x:]][suffix]), ch)\n",
    "        \n",
    "        pb += (lam*Pmle) + (one_min_lam*pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making the above modifications we get results that are more consistent with what would be expected:\n",
    "\n",
    "<img src=\"perplex0.png\">\n",
    "\n",
    "From this you can see that the model begins to overfit at 4gram. This could be the result of bad filtering in the above step or other bugs. Infact, I noticed when doing these fixes that the changes resulted in some of the probabilities in the calculation above resulting in probabilities above 1. The line I believed was causing this, and a line I found to be mathematically incorrect was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  pb += (lam*Pmle) + (one_min_lam*pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line was causing a sum where I am thinking that it is not needed. By changing this line to the following I was able to eliminate the probabilities being over 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  pb = (lam*Pmle) + (one_min_lam*pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, while I do believe that this line is more mathematically correct it resulted in much worse performance on the testing data:\n",
    "\n",
    "<img src='perplex1.png'>\n",
    "\n",
    "As we can see, the model overfits at 2gram now. While I believe the previous graph is more plausable I believe that the function that resulted in this graph is more mathematically correct. I think that both graphs may be the result of a bug somewhere in the logic for the $P_wb$ calculations. I have unfortunately run out of time to work through these bugs, though I am very curious where they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation via Perplexity\n",
    "Explore the effects of n-gram order using perplexity. Perform ten-fold cross-validation on the WSJ corpus. On each iteration, this will give you a different 90/10 training/test split; train a smoothed language model on the 9 training sections, and compute the average per-token perplexity of the tenth section. The slides from the language modeling lecture give the equation for perplexity computation (as does J&M chapter 4); you'll need to modify the equation a bit, since we're using log-probabilities. \n",
    "\n",
    "Now, try this for unigram, bigram, trigram, and 4-gram models. \n",
    "\n",
    "#### What to turn in\n",
    "* your cross-validation function. You are not suppose to use any cross-validation function from any module. You should implement it by yourself.\n",
    "* your perplexity function\n",
    "* cross-validation result for unigram, bigram, trigram, and 4-gram models on wsj.pos.gz\n",
    "* cross-validation result for unigram, bigram, trigram, and 4-gram models on wsj-normalized.pos.gz.\n",
    "* Answer following 2 questions: \n",
    "    * How does perplexity change as the model order size increases?\n",
    "    * How does perplexity change as the data changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for N Fold Cross Validation and Perplexity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#N_FOLD: generalized n_fold cross validation\n",
    "#\n",
    "#   # INPUTS\n",
    "#   data: the dataset as a list\n",
    "#   n: number of folds\n",
    "#   scoring_function: function used to evaluate\n",
    "#   param_list: list of parameters for scoring_function\n",
    "#\n",
    "#   # OUTPUTS\n",
    "#   score_list: a list of the scores for the different test runs\n",
    "def n_fold(data, n, scoring_function, param_list):\n",
    "    print(n, \" FOLD CROSS VALIDATION\")\n",
    "    # get lenght of corpus and use it to get test set size\n",
    "    size_of_data = len(data)\n",
    "    size_of_test_set = int(size_of_data/n)\n",
    "    \n",
    "    # score list holds onto results\n",
    "    score_list = []\n",
    "    \n",
    "    ###  n folds  ##\n",
    "    for x in range(n):\n",
    "        print(\"-------  FOLD\" , x, \" ------------\")\n",
    "        # build test set and trainging set\n",
    "        test_set = data[x*size_of_test_set:(x+1)*size_of_test_set]\n",
    "        training_set = data[:x*size_of_test_set]+data[(x+1)*size_of_test_set:]        \n",
    "        \n",
    "        # evaluate\n",
    "        score = scoring_function(test_set, training_set, *param_list)\n",
    "        print(\"Score: \",score)\n",
    "        score_list.append(score)\n",
    "    \n",
    "\n",
    "    print(\"\\nMean Score: \",sum(score_list)/float(len(score_list)))\n",
    "    \n",
    "    return score_list\n",
    "\n",
    "def n_fold_on_training(data, n, scoring_function, param_list):\n",
    "    print(n,\" FOLDING ON TRAINING\")\n",
    "    # get lenght of corpus and use it to get test set size\n",
    "    size_of_data = len(data)\n",
    "    size_of_test_set = int(size_of_data/n)\n",
    "    \n",
    "    # score list holds onto results\n",
    "    score_list = []\n",
    "    \n",
    "    print(\"Starting\")\n",
    "    \n",
    "    ###  n folds  ##\n",
    "    for x in range(0,n):\n",
    "        print(\"-------  FOLD\" , x, \" ------------\")\n",
    "        # build test set and trainging set\n",
    "        test_set = data[(x)*size_of_test_set:(x+1)*size_of_test_set]\n",
    "        training_set = data[:x*size_of_test_set]+data[(x+1)*size_of_test_set:]        \n",
    "        \n",
    "        # evaluate\n",
    "        score = scoring_function(test_set, training_set, *param_list)\n",
    "        print(\"Score: \",score)\n",
    "        score_list.append(score)\n",
    "            \n",
    "    print(\"\\nMean Score: \",sum(score_list)/float(len(score_list)))  \n",
    "\n",
    "    return score_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplex(test_set, training_set, order):\n",
    "    \n",
    "    # holds the cascading product\n",
    "    PP = BitWeight(1)\n",
    "    \n",
    "    # count the number of grams\n",
    "    N = 0.0\n",
    "    \n",
    "    # build model\n",
    "    count_list = count_list_builder(training_set, order)\n",
    "    \n",
    "    # tokenize and then get the grams\n",
    "    toks = tokenize(test_set)\n",
    "    grams = ngrams(toks, order)\n",
    "    \n",
    "    # for each gram, multiply into the cascading ghrams\n",
    "    for lines in grams:\n",
    "        N += 1.0\n",
    "        PP *= calculate_wb(lines[0], lines[1], count_list)\n",
    "    \n",
    "    # return the decimal form\n",
    "    return 2**((1/N)*PP.log())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whitten-Bell Perplexity 10 Fold Cross validation for 'wsj.pos'\n",
    "##### Unigram, Bigram, Trigram, and 4-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  FOLD CROSS VALIDATION\n",
      "-------  FOLD 0  ------------\n",
      "Score:  965.033203404\n",
      "-------  FOLD 1  ------------\n",
      "Score:  1030.53236006\n",
      "-------  FOLD 2  ------------\n",
      "Score:  992.010260191\n",
      "-------  FOLD 3  ------------\n",
      "Score:  1013.64542823\n",
      "-------  FOLD 4  ------------\n",
      "Score:  992.170878986\n",
      "-------  FOLD 5  ------------\n",
      "Score:  983.736779422\n",
      "-------  FOLD 6  ------------\n",
      "Score:  961.503379617\n",
      "-------  FOLD 7  ------------\n",
      "Score:  965.316053679\n",
      "-------  FOLD 8  ------------\n",
      "Score:  1029.93735751\n",
      "-------  FOLD 9  ------------\n",
      "Score:  1051.86799403\n",
      "\n",
      "Mean Score:  998.575369513\n"
     ]
    }
   ],
   "source": [
    "# 10 Fold Cross Validation for 'wsj.pos' showing results\n",
    "# Whitten-Bell Unigram\n",
    "tl = file_to_list('wsj.pos')\n",
    "_ = n_fold(tl[:10000],10, perplex, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  FOLD CROSS VALIDATION\n",
      "-------  FOLD 0  ------------\n",
      "Score:  1280.46972396\n",
      "-------  FOLD 1  ------------\n",
      "Score:  1357.63879836\n",
      "-------  FOLD 2  ------------\n",
      "Score:  1323.3727721\n",
      "-------  FOLD 3  ------------\n",
      "Score:  1337.25791609\n",
      "-------  FOLD 4  ------------\n",
      "Score:  1307.25999127\n",
      "-------  FOLD 5  ------------\n",
      "Score:  1304.9579425\n",
      "-------  FOLD 6  ------------\n",
      "Score:  1270.29549874\n",
      "-------  FOLD 7  ------------\n",
      "Score:  1266.71459653\n",
      "-------  FOLD 8  ------------\n",
      "Score:  1368.70247816\n",
      "-------  FOLD 9  ------------\n",
      "Score:  1378.21174042\n",
      "\n",
      "Mean Score:  1319.48814581\n"
     ]
    }
   ],
   "source": [
    "# Whitten-Bell Biigram\n",
    "_ = n_fold(tl[:10000],10, perplex, [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  FOLD CROSS VALIDATION\n",
      "-------  FOLD 0  ------------\n",
      "Score:  492.227562192\n",
      "-------  FOLD 1  ------------\n",
      "Score:  515.103302105\n",
      "-------  FOLD 2  ------------\n",
      "Score:  487.353028234\n",
      "-------  FOLD 3  ------------\n",
      "Score:  489.967960501\n",
      "-------  FOLD 4  ------------\n",
      "Score:  433.990069721\n",
      "-------  FOLD 5  ------------\n",
      "Score:  472.804617976\n",
      "-------  FOLD 6  ------------\n",
      "Score:  494.371105643\n",
      "-------  FOLD 7  ------------\n",
      "Score:  463.332879768\n",
      "-------  FOLD 8  ------------\n",
      "Score:  491.542129482\n",
      "-------  FOLD 9  ------------\n",
      "Score:  540.704746056\n",
      "\n",
      "Mean Score:  488.139740168\n"
     ]
    }
   ],
   "source": [
    "# Whitten-Bell Trigram\n",
    "_ = n_fold(tl[:10000],10, perplex, [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  FOLD CROSS VALIDATION\n",
      "-------  FOLD 0  ------------\n",
      "Score:  317.427139679\n",
      "-------  FOLD 1  ------------\n",
      "Score:  329.899679553\n",
      "-------  FOLD 2  ------------\n",
      "Score:  312.119505282\n",
      "-------  FOLD 3  ------------\n",
      "Score:  315.100664104\n",
      "-------  FOLD 4  ------------\n",
      "Score:  267.38591489\n",
      "-------  FOLD 5  ------------\n",
      "Score:  300.399039953\n",
      "-------  FOLD 6  ------------\n",
      "Score:  320.904056414\n",
      "-------  FOLD 7  ------------\n",
      "Score:  299.338542142\n",
      "-------  FOLD 8  ------------\n",
      "Score:  309.736566037\n",
      "-------  FOLD 9  ------------\n",
      "Score:  346.929954181\n",
      "\n",
      "Mean Score:  311.924106223\n"
     ]
    }
   ],
   "source": [
    "# Whitten-Bell 4-gram\n",
    "_ = n_fold(tl[:10000],10, perplex, [4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whitten-Bell Perplexity 10 Fold Cross validation for 'wsj-normalize.pos'\n",
    "##### Unigram, Bigram, Trigram, and 4-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  FOLD CROSS VALIDATION\n",
      "-------  FOLD 0  ------------\n",
      "Score:  385.314744887\n",
      "-------  FOLD 1  ------------\n",
      "Score:  362.588721062\n",
      "-------  FOLD 2  ------------\n",
      "Score:  345.103155197\n",
      "-------  FOLD 3  ------------\n",
      "Score:  325.047961849\n",
      "-------  FOLD 4  ------------\n",
      "Score:  292.448955251\n",
      "-------  FOLD 5  ------------\n",
      "Score:  301.972188781\n",
      "-------  FOLD 6  ------------\n",
      "Score:  334.213259241\n",
      "-------  FOLD 7  ------------\n",
      "Score:  372.325382191\n",
      "-------  FOLD 8  ------------\n",
      "Score:  333.449559403\n",
      "-------  FOLD 9  ------------\n",
      "Score:  287.906906725\n",
      "\n",
      "Mean Score:  334.037083459\n"
     ]
    }
   ],
   "source": [
    "# 10 Fold Cross Validation for 'wsj-normalized.pos' showing results\n",
    "# Whitten-Bell Unigram\n",
    "tln = file_to_list('wsj-normalized.pos')\n",
    "_ = n_fold(tln[:10000],10, perplex, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  FOLD CROSS VALIDATION\n",
      "-------  FOLD 0  ------------\n",
      "Score:  536.668123777\n",
      "-------  FOLD 1  ------------\n",
      "Score:  504.52841606\n",
      "-------  FOLD 2  ------------\n",
      "Score:  487.908528265\n",
      "-------  FOLD 3  ------------\n",
      "Score:  455.026915521\n",
      "-------  FOLD 4  ------------\n",
      "Score:  410.815966191\n",
      "-------  FOLD 5  ------------\n",
      "Score:  426.592805702\n",
      "-------  FOLD 6  ------------\n",
      "Score:  466.590636597\n",
      "-------  FOLD 7  ------------\n",
      "Score:  512.722089735\n",
      "-------  FOLD 8  ------------\n",
      "Score:  470.998593417\n",
      "-------  FOLD 9  ------------\n",
      "Score:  403.667070549\n",
      "\n",
      "Mean Score:  467.551914581\n"
     ]
    }
   ],
   "source": [
    "# Whitten-Bell Bigram\n",
    "_ = n_fold(tln[:10000],10, perplex, [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  FOLD CROSS VALIDATION\n",
      "-------  FOLD 0  ------------\n",
      "Score:  243.518151366\n",
      "-------  FOLD 1  ------------\n",
      "Score:  233.307136954\n",
      "-------  FOLD 2  ------------\n",
      "Score:  218.783410549\n",
      "-------  FOLD 3  ------------\n",
      "Score:  208.789728743\n",
      "-------  FOLD 4  ------------\n",
      "Score:  180.233674194\n",
      "-------  FOLD 5  ------------\n",
      "Score:  193.155898579\n",
      "-------  FOLD 6  ------------\n",
      "Score:  223.024881755\n",
      "-------  FOLD 7  ------------\n",
      "Score:  229.468134118\n",
      "-------  FOLD 8  ------------\n",
      "Score:  213.999522079\n",
      "-------  FOLD 9  ------------\n",
      "Score:  196.872233605\n",
      "\n",
      "Mean Score:  214.115277194\n"
     ]
    }
   ],
   "source": [
    "# Whitten-Bell Trigram\n",
    "_ = n_fold(tln[:10000],10, perplex, [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  FOLD CROSS VALIDATION\n",
      "-------  FOLD 0  ------------\n",
      "Score:  165.363927334\n",
      "-------  FOLD 1  ------------\n",
      "Score:  159.277126192\n",
      "-------  FOLD 2  ------------\n",
      "Score:  149.274982091\n",
      "-------  FOLD 3  ------------\n",
      "Score:  143.877264043\n",
      "-------  FOLD 4  ------------\n",
      "Score:  121.034998493\n",
      "-------  FOLD 5  ------------\n",
      "Score:  132.26827235\n",
      "-------  FOLD 6  ------------\n",
      "Score:  154.762422334\n",
      "-------  FOLD 7  ------------\n",
      "Score:  156.724796221\n",
      "-------  FOLD 8  ------------\n",
      "Score:  145.243576228\n",
      "-------  FOLD 9  ------------\n",
      "Score:  137.176892952\n",
      "\n",
      "Mean Score:  146.500425824\n"
     ]
    }
   ],
   "source": [
    "# Whitten-Bell 4-gram\n",
    "_ = n_fold(tln[:10000],10, perplex, [4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "##### 1. How does perplexity change as the model order size increases?\n",
    "It can be seen from the results of both the 'wsj.pos' and the 'wsj-normalized.pos' that as the order of the model increases the perplexity decreases. This indicates that the higher order models we see here are more accurate than the lower ones.\n",
    "\n",
    "##### 2. How does perplexity change as the data changed?\n",
    "It can be seen in the results that the model was more acurate in prediction the outcomes of the normalized file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Self assessment:</font>\n",
    "\n",
    "Although my perplexity calculations are not completly correct, I believe the code in this section is. I believe the inconsistencies in the output with the provided solution are a result of the $P_wb$ calculation and not the result of the code in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
