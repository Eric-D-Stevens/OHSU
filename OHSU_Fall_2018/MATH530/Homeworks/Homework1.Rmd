---
title: "Homework 1"
author: "Eric Stevens"
date: "10/10/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# 
library(MASS)
library(tidyverse)
```

## Question 1:

```{r}

body_vs_heart <- ggplot(cats, aes(Bwt,Hwt)) +
                  geom_point() +
                  geom_smooth(method = "lm", se = T)

body_vs_heart

```

The above graph shows that a linear regression does a fairly good job
at modeling the relationship between a cats heart weight and its body 
weight. The data is organized in a highly linear fashion. It is useful 
to note that body weight seems to be democratized allowing us to see that 
there are several points on either side of the line at each descritized 
recorded body weight. This shows that we would be hard pressed to find a 
model that preformed better than the linear one because there is not 
enough data to do anything much more fancy. Through the use of the standard 
error marker we can see that there remains a very low amount of error 
through the center of our data set and out to the edges. The SE does grow 
towards the higher end of graph, but this is likely due to a lack of data 
points at the extreme end. 

Now we will calculate the co-variance of the parameters as follows:

```{r}
with(cats, cov(Bwt, Hwt))
```


## Question 2:


```{r}
# convert units for part c
cats_imperial <- cats %>%
mutate(bwt_lbs = Bwt * 2.205,
hwt_lbs = Hwt * 0.0022046)

body_vs_heart_imperial <- ggplot(cats_imperial, aes(bwt_lbs,hwt_lbs)) +
                  geom_point() +
                  geom_smooth(method = "lm", se = T)

body_vs_heart_imperial


```

We can see that changing the units of the data we are plotting has not 
changed much. We have different axis. We have a slightly different grid
behind the graph. The overall shape of the data and relative position 
of the data points has not changed at all.

Now we will calculate the co-variance of the parameters as follows:

```{r}
with(cats_imperial, cov(bwt_lbs, hwt_lbs))
```

As we can see, the number we obtained for the co-variance in pounds is 
much different than the one that we obtained when we were on the g/kg 
scale. The difference is to be expected cause the value of the co-variance 
is sensitive to the scale being used. The large scale difference is due 
to the conversion from grams to pounds on one of the axis. The value 
can be attributed to the 2.2x conversion.

Now lets have a look at the correlations:

```{r}
with(cats, cor(Bwt, Hwt))
with(cats_imperial, cor(bwt_lbs, hwt_lbs))
```

Here we can see that correlations for either set of axis is exactly the 
same. The correlation is an attribute that is all proportional, and 
therefore is unaffected by the altering of the axis.

## Question 3: 

Now we will convert our axis to z scores. This means that were converting 
them to the distance they are away from the mean in terms of standard 
deviation. This is done as follows:

```{r}
z_bwt_in_kg <- scale(cats$Bwt)
z_hwt_in_g <- scale(cats$Hwt)
```

To ensure that this operation is has been executed correctly we can 
check two outcomes of the definition of the z score.

First, the mean of a z score must be 0:
```{r}
mean(z_bwt_in_kg)
mean(z_hwt_in_g)
```

The numbers above are not 0s due to floating point rounding errors. This 
can be assumed due to the fact that the precision of the measurement is 
far higher than any of our data allowed for and is extremely close to 0.

The next outcome is that a z score must have a standard deviation equal 
to 1:
```{r}
sd(z_bwt_in_kg)
sd(z_hwt_in_g)
```

As expected, the standard deviation for both values is one. We have 
confirmed that our conversion to z scores was successful.

Now lets examine the co-variance of the z scores:
```{r}
cov(z_bwt_in_kg, z_hwt_in_g)
```

Here we have a number that we have not seen yet from either the 
co-variance calculations in terms of g/kg or lbs.

Lets further examine the correlation:

```{r}
cor(z_bwt_in_kg, z_hwt_in_g)
```

Wow! The correlation of the z scores exactly matches the co-variance of the 
z scores! Not only that, but as expected the correlation between the z 
scores exactly matches the correlations of the kg/g and lb measurements. 
From this example I am lead to believe that a correlation is a co-variance 
that is represented in terms of standard deviation.

Lets look deeper into the difference of between correlation and co-variance:

Co-variance is defined by the following equations:

$$\displaystyle \frac{\sum_{i = 1}^{n}(x_i-\mu_x)(y-\mu_y)}{n-1}$$

Correlation is defined by:
$$\displaystyle \frac{\sum_{i = 1}^{n}(x_i-\mu_X)(y-\mu_Y)}{(n-1)(\sigma_X\sigma_Y)}$$

By looking at these equations it is easy to see why when we compare the 
z score correlation to the co-variance, they are the same. By definition 
z scores have a standard deviation of one. This makes the addition to the 
denominator irrelevant as $\sigma_X\sigma_Y = 1$. Therefore the co-variance is equal to the correlation. 

The addition of the product of the standard deviations in the denominator 
also explains why correlation is insensitive to linear transformation. 
Even if the scales change, the fact that they are being divided by their 
standard deviations forces the result to be in terms of a scale of 
standard deviation. 