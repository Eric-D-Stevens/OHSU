---
title: "CM Lab 2.2 markdown"
author: "Eric Stevens"
date: "10/2/2018"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

***
## 1: Overview

Load required packages:
```{r}
library(moderndive)
library(tidyverse)
library(skimr)
```


Set the column names:
```{r}
crimenames <- c("county", "region_name", "region_code",
               "criminals", "public_houses", "school_attendance",
               "worship_attendance")
```
Load the data:

```{r}
crime <- read_table("https://ohsu-math630-fall-2018.netlify.com/data/beerhall.dat",
                    col_names = crimenames)
```



### $$\hat{criminals} = b_0 + b_1{pubs}$$

***

## 2: EDA

* Raw Values:
```{r}
crime
```
* Summary statistics of variables of interest:
```{r}
crime %>%
  skim()
```

* Get scatter plot of variable of interest vs target.

```{r}
ggplot(crime, aes(public_houses, criminals)) + geom_point()
```


***
## 3: Simple linear regression

#### Part 1:

Fit linear regression model to the data:
```{r}
score_model <- lm(criminals ~ public_houses, data = crime)
score_model
```

Model the object:

```{r}
get_regression_table(score_model)
```

The equation of the linear regression is as follows:

$$\hat{y} = 109.340 + 0.116{x}$$

#### Part 2:

The values obtained in the linear regression do match the EDA. The interpretation of 
the of the linear regression model is that there is a positive correlation between the
number of public houses and the total number of criminals. To be precise, with a 
coefficient of 0.116, the regression approximates that for every if you build 10 more 
public houses you will have one additional criminal. The intercept of 109 implies that 
even if there were no public houses you would still have 109 criminals. 

The graph seems to hint at a stronger correlation between the number of public houses and 
and criminals than the linear regression does. I think this is a result of using SSE as 
our function to minimize coupled with the fact that there are a several outliers that 
change the trend.


***
## 4 Observed / fitted

#### Part 1:

We obtain information about the residuals using the following code:

```{r}
regression_points <- get_regression_points(score_model) 
regression_points %>% filter(ID==20 | ID==23)
```

The observed and fitted values for the requested counties are as follows:

ID   | County    | Public Houses | Observed  | Fitted 
---- | --------- | ------------- | --------- | -------
20   | Cornwall  |      87       |   66      | 119.450
23   | Monmouth |     241       |   350     | 150.012

Due to my own beliefs I am in no position to comment on the good reverends 
ideas of objective morality.


#### Part 2: 

Now we filter the results of the regression model for 1) the minimum number of criminals 
overall, and 2) the largest negative difference between the observed value and the fitted 
value.

This represents the least number of criminals overall and the county with  the least amount
of criminals compared to what was predicted.

```{r}
regression_points %>% filter( criminals == min(criminals) | residual == min(residual))
```
```{r}
crime[20,]
crime[33,]
```

* Cornwall is the county with the least number of criminals overall.

* Derby is the county with the largest difference between fitted number of criminals 
and actually number of criminals.


***
## 5: Residual analysis

#### Part 1:

Now we will perform a residual analysis. First lets look at a scatter plot of the residuals 
and 

```{r}
ggplot(regression_points, aes(x = public_houses, y = residual)) +
  geom_point() +
  labs(x = "Public Houses", y = "Residual") +
  geom_hline(yintercept = 0, col = "blue", size = 1)
```

From our scatter plot we can see that there is ***no symetric pattern***. This is good 
because it implies that the linear model is appropriate for the estimation. If there had 
been a symmetric pattern, we would know that there may be a higher order model that would 
better capture the relationship we are trying to model.

#### Part 2:

Lets plot the distribution density of the residuals in terms of their magnitude:

```{r}
ggplot(regression_points, aes(x = residual)) +
  geom_density() +
  labs(x = "Residual") + geom_vline(data = regression_points, aes(xintercept = 0, color="red")) + 
  guides(color=F)
```

From this plot we can see that there is a fairly even distribution across the 0 line. 
In other words, there were about as many negative residuals as there were positive. There 
appears to be a higher density of negative residuals near the 0 mark, put the tail of the 
positive residuals extends further, therefore it appears symmetric. 